[
 {
  "title": "Four short links: 13 May 2020",
  "content": "\nThe Confessions of Marcus Hutchins, the Hacker Who Saved the Internet \u2014 Story of the MalwareTech security researcher who foiled WannaCry, only to be arrested by the FBI for having sold malware as a kid. Young Marcus had terrible opsec.\nThe Next Social Era is Here \u2014 Arguing we\u2019re ready for another boom in social software. First, the pandemic is creating a new topology of psychological and emotional needs. [\u2026] Second, the work environment is now open game for new social products. Two reasons for this. First, we see how good communication can be with consumer products and demand the same excellence in our work lives. But second, and newer, is that in the last few months, the distance between our work identities and our home identities have blurred. \nCookies, Chaos and the Browser: Meet Lou Montulli \u2014 An interview with a Web oldbie, the guy who worked on https, cookies, forms, animated GIFs, but who will always have a treasured spot in my heart for the Curses-based text-mode browser Lynx.\nWhy we at $FAMOUS_COMPANY Switched to $HYPED_TECHNOLOGY \u2014 Hilarious parody of a tech announcement.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/KQ5CMAVsal8/"
 },
 {
  "title": "Four short links: 12 May 2020",
  "content": "\nflecs \u2014 a Fast and Lightweight ECS (Entity Component System). An ECS [\u2026] is a way to organize code that is mostly used in gaming and simulation projects. ECS code generally performs better than traditional OOP, and is typically easier to reuse. The main differences between ECS and OOP are composition is a first class citizen in ECS, and that data is represented as plain data types rather than encapsulated classes.\nTwo Ways to Categorize Errors \u2014 two dimensions that are useful for categorizing errors: Exceptional Errors vs. Failures; Internal vs. External Errors. Often the first step to solving a problem is finding the right lens to look at it through.\nChatting with Glue \u2014 An interestingly-presented set of ideas about how we might offer more structural affordances in chat software to assist comprehension. I\u2019m not doing it justice: it\u2019s provocative. How to help people think better with software is a conversation I\u2019m always up for, so this has really hit my buttons.\nThe Best Books on the Politics of Information \u2014 If we are to understand how politics and markets work at the moment, we need to pay attention to how algorithms work, and how the economy is being remade from the ground up by these new forms of information processing. [\u2026] My starting point was \u2018Okay, if we started thinking about the core of a curriculum for a course on this topic, what could we include?\u2019 These would be the core books you would want as part of the discussion.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/V6dF5m1ZxBM/"
 },
 {
  "title": "When models are everywhere",
  "content": "You probably interact with fifty to a hundred machine learning products every day, from your social media feeds and YouTube recommendations to your email spam filter and the updates that the New York Times, CNN, or Fox News decide to push, not to mention the hidden models that place ads on the websites you visit, and that redesign your \u2018experience\u2019 on the fly. Not all models are created equal, however: they operate on different principles, and impact us as individuals and communities in different ways. They differ fundamentally from each other along dimensions such as alignment of incentives between stakeholders, \u201ccreep factor\u201d, and the nature of how their feedback loops operate.\u00a0\n\n\n\nTo understand the menagerie of models that are fundamentally altering our individual and shared realities, we need to build a typology, a classification of their effects and impacts. This typology is based on concepts such as the nature of different feedback loops in currently deployed algorithms, and how incentives can be aligned and misaligned between various stakeholders. Let\u2019s start by looking at how models impact us.\n\n\n\nSCREENS, FEEDBACK, AND \u201cTHE ENTERTAINMENT\u201d\n\n\n\nMany of the models you interact with are mediated through screens, and there\u2019s no shortage of news about how many of us spend our lives glued to them. Children, parents, friends, relatives: we are all subject to screens, ranging from screens that fit on our wrist to screens that occupy entire walls. You may have seen loved ones sitting on the couch, watching a smart TV while playing a game on an iPad, texting on their smartphones, and receiving update after update on their Apple Watch, a kaleidoscope of screens of decreasing size. We even have apps to monitor and limit screen time. Limiting screen time has been an option on iPhones for over a year, and there are apps for iPhones and Android that not only monitor your childrens\u2019 screen time, they let you reward them for doing their chores or their homework by giving them more. Screen time has been gamified: where are you on the leaderboard?\u00a0\n\n\n\nWe shouldn\u2019t be surprised. In the 70s, TV wasn\u2019t called the \u201cboob tube\u201d for nothing. In David Foster Wallace\u2019s novel Infinite Jest, there is a video tape known as \u201cThe Entertainment.\u201d When somebody watches it, they are unable to look away, no longer caring about food, shelter or sleep, and they eventually enter a state of immobile, catatonic bliss. There\u2019s a telling sequence in which more and more people approach those watching it to see what all the hullabaloo is about and also end up with their eyes glued to the screen.\u00a0\n\n\n\nInfinite Jest was published in 1996, just as the modern Web was coming into being. It predates recommendation engines, social media, engagement metrics, and the recent explosion of AI, but not by much. And like a lot of near-future SciFi, it\u2019s remarkably prescient. It\u2019s a shock to read a novel about the future, and realize that you\u2019re living that future.\u00a0\n\n\n\n\u201cThe Entertainment\u201d is not the result of algorithms, business incentives and product managers optimizing for engagement metrics. There\u2019s no Facebook, Twitter, or even a Web; it\u2019s a curious relic of the 80s and 90s that The Entertainment appeared in the form of a VHS tape, rather than an app. \u201cThe Entertainment\u201d is a tale of the webs that connect form, content and addiction, along with the societal networks and feedback loops that keep us glued to our screens. David Foster Wallace had the general structure of the user\u2013product interaction correct. That loop isn\u2019t new, of course; it was well-known to TV network executives. Television only lacked the immediate feedback that comes with clicks, tracking cookies, tracking pixels, online experimentation, machine learning, and \u201cagile\u201d product cycles.\u00a0\u00a0\n\n\n\nDoes \u201cThe Entertainment\u201d show people what they want to see? In a highly specific, short-term sense, possibly. In a long-term sense, definitely not. Regardless of how we think of ourselves, humans aren\u2019t terribly good at trading off short-term stimulus against long-term benefits. That\u2019s something we\u2019re all familiar with: we\u2019d rather eat bacon than vegetables, we\u2019d rather watch Game of Thrones than do homework, and so on.\u00a0 Short-term stimulus is addictive: maybe not as addictive as \u201cThe Entertainment,\u201d but addictive nonetheless.\u00a0\u00a0\n\n\n\nYOUTUBE, CONSPIRACY, AND OPTIMIZATION\n\n\n\nWe\u2019ve seen the same argument play out on YouTube: when their recommendation algorithm was optimized for how long users would keep their eyeballs on YouTube, resulting in more polarizing conspiracy videos being shown, we were told that YouTube was showing people what they wanted to see. This is a subtle sleight-of-mind, and it\u2019s also wrong. As Zeynep Tufekci points out, this is analogous to an automated school cafeteria loading plates with fatty, salty, and sweet food because it has figured out that\u2019s what keeps kids in the cafeteria the longest. What\u2019s also interesting is that YouTube never wrote \u2018Show more polarizing conspiracy videos\u2019 into their algorithm: that was merely a result of the optimization process. YouTube\u2019s algorithm was measuring what kept viewers there the longest, not what they wanted to see, and feeding them more of the same. Like sugar and fat, conspiracy videos proved to be addictive, regardless of the viewer\u2019s position on any given cause. If \u201cThe Entertainment\u201d were posted to YouTube, it would be highly recommended on the platform: viewers can\u2019t leave. It\u2019s the ultimate virtual roach trap. If that\u2019s not engagement, what is? But it\u2019s clearly not what viewers want\u2013viewers certainly don\u2019t want to forget about food and shelter, not even for a great TV show.\u00a0\n\n\n\nOne result of this is that in 2016, out of 1,000 videos recommended by YouTube after an equal number of searches for \u201cTrump\u201d and \u201cClinton\u201d, 86% of recommended videos favored the Republican nominee. In retrospect, the recommendation algorithm\u2019s \u201clogic\u201d is inescapable. If you\u2019re a Democrat, Trump videos made you mad. If you\u2019re a Republican, Trump\u2019s content was designed to make you mad. And anger and polarization are bankable commodities that drive the feedback loop in an engagement-driven world.\u00a0\n\n\n\nAnother result is the weirdness encountered in certain parts of kids\u2019 Youtube, such as \u201csurprise Eggs videos [that] depict, often at excruciating length, the process of unwrapping Kinder and other egg toys.\u201d Some of these have up to 66 million views. These are all results of business incentives for both YouTube and its content providers, the metrics used to measure success and the power of feedback loops on an individual level and in society, as manifested in modern big tech recommender systems.\u00a0\n\n\n\nIt\u2019s important to note that the incentives of YouTube, its advertisers, and its users are often misaligned, in that users searching for \u201creal news\u201d continually end up being shunted down conspiracy theory and \u201cfake news\u201d rabbit holes due to the mixed incentive structure of the advertising-based business model. Such mixed incentives were even noted by Google founders Sergey Brin and Larry Page in their 1998 paper The Anatomy of a Large-Scale Hypertextual Web Search Engine, which details their first implementation of the Google Search algorithm. In Appendix A, aptly titled \u2018Advertising and Mixed Motives\u2019, Brin and Page state explicitly that \u201cthe goals of the advertising business model do not always correspond to providing quality search to users\u201d and \u201cwe expect that advertising funded search engines will be inherently biased towards the advertisers and away from the needs of the consumers.\u201d *Gulp*. Also note that they refer to the user of Search here as a consumer.\n\n\n\nFEEDBACK LOOPS, FILTER BUBBLES, ECHO CHAMBERS, AND INCENTIVE STRUCTURES\n\n\n\nYouTube is a case study on the impact of feedback loops on the individual: if I watch something for a certain amount of time, YouTube will recommend similar things to me, for some definition of similar (similarity is defined by broader societal interactions with content), resulting in what we now call \u201cfilter bubbles\u201d, a term coined by internet activist Eli Pariser in his 2011 book The Filter Bubble: What the Internet Is Hiding from You. Netflix\u2019s algorithm has historically resulted in similar types of recommendations and filter bubbles (although business incentives are now forcing them to surface more of their own content).\n\n\n\nTwitter and Facebook have feedback loops that operate slightly differently, because every user can be both a content provider and a consumer, and the recommendations arise from a network of multi-sided interactions. If I\u2019m sharing content and liking content, the respective algorithms will show me more that is similar to both, resulting in what we call \u201cecho chambers.\u201d These echo chambers represent a different kind of feedback that doesn\u2019t just involve a single user: it\u2019s a feedback loop that involves the user and their connections. The network that directly impacts me is that of my connections and the people I follow.\u00a0\n\n\n\nWe don\u2019t have to look far to see other feedback loops offline. There are runaway feedback loops in \u201cpredictive policing\u201d, whereby more police are sent to neighborhoods with higher \u201creported & predicted crime,\u201d resulting in more police being sent there and more reports of crime and so on. Due to the information and power asymmetries at play here, along with how such feedback loops discriminate against specific socioeconomic classes, projects such as White Collar Crime Risk Zones, which maps predictions of white collar crime, are important. An application that hospitals use to screen for patients with high-risk conditions that require special care wasn\u2019t recommending that care for black patients as often; white patients spend more on health care, making their conditions appear to be more serious. While these applications look completely different, the feedback loop is the same. If you spend more, you get more care; if you police more, you make more arrests. And the cycle goes on. Note that in both cases, a major part of the problem was also the use of proxies for metrics: cost as a proxy for health, police reports a proxy for crime, not dissimilar to the use of Youtube view-time as a proxy for what a viewer wants to watch (for more on metrics and proxies, we highly recommend the post The problem with metrics is a big problem for AI by Rachel Thomas, Director of the Center for Applied Data Ethics at USF). There are also interaction effects between many models deployed in society that mean they feedback into each other: those most likely to be treated unfairly by the healthcare algorithm are more likely to be discriminated against by models used in employment hiring flows and more likely to be targeted by predatory payday loan ads online, as detailed by Cathy O\u2019Neil in Weapons of Math Destruction.\n\n\n\nGoogle search operates at another scale of networked feedback, that of everybody. When I search for \u201cArtificial Intelligence,\u201d the results aren\u2019t only a function of what Google knows about me, but also of how successful each link has been for everybody that has seen it previously. Google Search also operates in a fundamentally different way to many modern recommendation systems: historically, it has optimized its results to get you off its platform, though recently its emphasis has shifted. Whereas so many tech companies optimize for engagement with their platforms, trying to keep you from going elsewhere, Google\u2019s incentive with Search was to direct you to another site, most often for the purpose of discovering facts. Under this model, there is an argument that the incentives of Google, advertisers, and users were all aligned, at least when searching for basic facts: all three stakeholders want to get the right fact in front of the user, at least in theory. This is why Search weighs long clicks more heavily than short clicks (the longer the time before the user clicks back to Google, the better).\u00a0 Now that Google has shifted to providing answers to questions rather than links to answers, they are valuing engagement with their platform over engagement with other advertisers; as an advertiser, you\u2019re more likely to succeed if you advertise directly on Google\u2019s result page. Even more recently, Google announced its incorporation of BERT (Bidirectional Encoder Representations from Transformers, a technology enabling \u201canyone to train their own state-of-the-art question answering system\u201d) into Search, which will allow users to make more complex and conversational queries and will enable you to \u201csearch in a way that feels natural for you\u201d (according to Google, this is \u201cone of the biggest leaps forward in the history of Search\u201d). Fundamental changes in Search to encourage more complex queries could result in a shift of incentives.\u00a0\n\n\n\nAlso, this theoretical alignment of incentives between Google, advertisers, and users is an idealization. In practice, Google search encodes all types of cultural and societal biases, such as racial discrimination, as investigated in Safiya Noble\u2019s Algorithms of Oppression. An example of this is that, for many years, when using Google image search with the keyword \u201cbeautiful,\u201d the results would be dominated by photos of white women. In the words of Ruha Benjamin, Associate Professor of African American Studies at Princeton University, \u201crace and technology are co-produced.\u201d\u00a0\u00a0\n\n\n\nA final word (for now) on developing healthy Google Search habits and practices: know that the SEO (Search Engine Optimization) industry is worth close to $80 billion and that the way you\u2019re served results and the potential mis-alignment of incentives depends on whether your search is informational (searching for information, such as \u201cWho was the 44th President of the United States?\u201d), navigational (searching for a particular website, such as \u201cWikipedia\u201d), or transactional (searching to buy something, such as \u201cBuy Masterclass subscription\u201d). Keep a skeptical mind about the results you\u2019re served! Personalization of search results may be handy in the short-term.\u00a0 However, when making informational searches, you\u2019re being served what you regularly assume is ground truth but is tailored to you, based on what Google already knows about your online and, increasingly, offline behavior. There is also an information asymmetry, in that you don\u2019t know what Google knows about you, and how that information plays into the incentives of Google\u2019s ad-based business model. For informational searches, this could be quite disturbing. As Jaron Lanier points out in Ten Arguments for Deleting Your Social Media Accounts Right Now, how would you feel if Wikipedia showed you and I different histories, based on our respective browser activities? To take this a step further, what if Wikipedia tailored the \u201cfacts\u201d served to us as a function of an ad-based business model?\n\n\n\nFor advertisers, incentive systems are also strangely skewed. We recently searched for Stitch Fix, the online personal styling service. This is a basic navigational search and Google could easily have served us the Stitch Fix website and they did, but above it were two advertisements: the first one was for Stitch Fix and the second one was for Trunk Club, a Stitch Fix competitor. This means that Trunk Club is buying ads for the keywords of their competitor, a common practice, and Stitch Fix then had to engage in defensive advertising due to how much traffic Google Search has, even when the user is clearly looking for their product! As a result, the user sees only ads above the scroll (at least on a cell phone) and needs to scroll down to find the correct and obvious search result. There is an argument that, if a user is explicitly searching to buy a product, it should be illegal for Google to force the product in question into defensive advertising.\n\n\n\nTOWARDS A TYPOLOGY OF MODEL IMPACT AND EFFECTS\n\n\n\nYouTube, the Facebook feed, Google Search, and Twitter are examples of modern algorithms and models that alter our perceptions of reality; applications like predictive policing reflect biased perceptions of reality that may have little to do with actual reality\u2013indeed, these models create their own realities, becoming self-fulfilling prophecies. They all operate in different ways and on different principles. The nature of the feedback loops, the resulting phenomena, and the alignment of incentives between user, platform, content providers and advertisers are all different. In a world that\u2019s increasingly filled with models, we need to assess their impact, identify challenges and concerns, and discuss and implement paths in the solution space.\n\n\n\nThis first attempt at a model impact and effect classification probed several models that are part of our daily lives by looking at the nature of their feedback loops and the alignment of incentives between stakeholders (model builders, users, and advertisers). Other key dimensions to explore include \u201ccreep\u201d factor, \u201chackability\u201d factor, and how networked the model itself is (is it constantly online and re-trained?). Such a classification will allow us to assess the potential impact of classes of models, consider how we wish to interact with them, and to propose paths forward. This work is part of a broader movement of users, researchers, and builders who are actively engaged in discovering and documenting how these models work, are deployed, and what their impacts are. If you are interested in exploring this space, we encourage you to check out the non-exhaustive reading list below.\n\n\n\n***\n\n\n\nThe authors would like to thank Shira Mitchell for valuable feedback on an early draft of this essay and Manny Moss for valuable feedback on a late draft.\n\n\n\nREADING LIST\n\n\n\nModel Cards for Model Reporting by Mitchell et al.Datasheets for Datasets by Gerbu et al.Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science by Bender & FriedmanAnatomy of an AI System by Crawford and JolerAlgorithms of Oppression by Safiya Umoja NobleWeapons of Math Destruction by Cathy O\u2019NeilRace after Technology by Ruha BenjaminAutomating Inequality by Virginia EubanksTwitter and Tear Gas by Zeynep TufekciIt\u2019s Complicated: The Social Lives of Networked Teens by danah boydTen Arguments for Deleting Your Social Media Accounts Right Now by Jaron LanierRuined by Design by Mike MonteiroAI Now Report 2018 by Whittaker et al.Owning Ethics: Corporate Logics, Silicon Valley, and the Institutionalization of Ethics by Jacob Metcalf, Emanuel Moss, and danah boyd (Data & Society)21 Fairness Definitions and Their Politics, a tutorial by Arvind Narayanan at FAT* 2018Prediction-Based Decisions and Fairness: A Catalogue of Choices, Assumptions, and Definitions by Mitchell et al.The problem with metrics is a big problem for AI by Rachel ThomasEthical Principles, OKRs, and KPIs: what YouTube and Facebook could learn from Tukey by Chris WigginsAlgorithmic Accountability: A Primer by Caplan et al. (Data & Society)The Digital Defense Playbook by Our Data BodiesThe Algorithmic Justice League\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/sGh3eBhuYOo/"
 },
 {
  "title": "Four short links: 11 May 2020",
  "content": "\nOragono \u2014 a modern IRC server written in Go.\nDeepFake Cartoon Voices \u2014 Fifteen.ai is a text-to-speech tool that you can use to generate 44.1 kHz voices of various characters. The voices are generated in real time using multiple audio synthesis algorithms and customized deep neural networks trained on very little available data (between 55 seconds and 120 minutes of clean dialogue for each character). This project demonstrates a significant reduction in the amount of audio required to realistically clone voices while retaining their affective prosodies.\nSystem Programming Book \u2014 CS241 \u201cIntro to Systems Programming\u201d textbook that was created in a wiki by University of Illinois students over 5 years.\nRealizing Quality Improvement Through Test Driven Development: Results and Experiences of Four Industrial Teams \u2014 The results of the case studies indicate that the pre-release defect density of the four products decreased between 40% and 90% relative to similar projects that did not use the TDD practice. Subjectively, the teams experienced a 15\u201335% increase in initial development time after adopting TDD.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/qa0FsPUaJS0/"
 },
 {
  "title": "Four short links: 8 May 2020",
  "content": "\nMathematics for Machine Learning \u2014 We wrote a book on Mathematics for Machine Learning that motivates people to learn mathematical concepts. The book is not intended to cover advanced machine learning techniques because there are already plenty of books doing this. Instead, we aim to provide the necessary mathematical skills to read those other books.\nCards Against Containers \u2014 nerd cards a-la Cards Against Humanity. (But without the swears.)\nOpenSAFELY \u2014 a new secure analytics platform for electronic health records in the NHS, created to deliver urgent results during the global COVID-19 emergency. It is now successfully delivering analyses across more than 24 million patients\u2019 full pseudonymised primary care NHS records, with more to follow shortly. All our analytic software is open for security review, scientific review, and re-use. An amazing collaborative piece of work that you can read about in Ben Goldacre\u2019s thread.\nRadar Trends to Watch in May 2020 \u2014 Mike Loukides\u2019s roundup of weak signs of the future.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/fFqKH7WawVM/"
 },
 {
  "title": "Radar trends to watch: May 2020",
  "content": "After last month\u2019s \u201call coronavirus, all the time\u201d report, I was concerned that this month would be more of the same.\u00a0 And there is, indeed, a lot of coronavirus. But there are many other trends and interesting items to look at\u2013possibly a sign that people are working effectively from home.\n\n\n\nCoronavirus\n\n\n\nCoronavirus prompts serious discussion of changes to the financial system. There\u2019s no doubt that money\u2019s dirty; and it isn\u2019t terribly useful in the context of \u201csocial distancing.\u201d Rethinking our financial system might lead to a public venmo, or even further to a digital dollar.\u00a0 (China is the leader here\u2013by a large margin.)\n\n\n\nCoronavirus and game play: Not surprisingly, COVID-19 has led to a big surge in game play and virtual reality. Might surviving isolation during a pandemic be the killer app for VR?\u00a0 (This trend arrived too late to help the VR startup Magic Leap, which appears to be failing.) Fred Wilson says, wisely I think, that social isolation will teach how much we crave being in \u201creal life.\u201d\n\n\n\nIt\u2019s hardly news that misinformation about Coronavirus is proliferating. The big question is whether automated attempts to stop that proliferation will succeed. YouTube, Twitter, and Facebook (including WhatsApp) are cracking down. Facebook is referring people who see misinformation to \u201cauthoritative resources.\u201d\n\n\n\nI haven\u2019t heard as much about Citizen Science in the past few years, but it\u2019s making a reappearance. Coronavirus binder designs (proteins that bind to Coronavirus) modeled by citizen scientists, are in the pipeline for testing. Fold-it is a game where you design proteins (protein folding) to achieve some goal\u2013in this case, binding to Coronavirus.\n\n\n\nCitizens are also playing a role on the front lines, with community-run COVID-19 testing.\u00a0 (I\u2019ve also seen pleas for citizens willing to help with contact tracing.)\n\n\n\nApple and Google are collaborating on OS-level tools for privacy-protecting contact tracing that will interoperate between Android and iOS. (Apps will be implemented by third parties, presumably healthcare organizations.) Germany was working on its own framework for contact tracing using cell phone apps, but it is now backing the Apple-Google collaboration.\u00a0\n\n\n\nWill we see \u201cre-shoring\u201d of jobs because of coronavirus? Outsourcing isn\u2019t as attractive when lockdowns limit the supply of offshore labor, and it\u2019s impossible to visit overseas contractors.\u00a0 Another consequence will be the increased use of AI, particularly in customer service.\n\n\n\nRobotics\n\n\n\nXenobots are living (literally) programmable robots, assembled from cultured frog skin cells.\u00a0\n\n\n\nFarming is very high tech. A European project called ROMI is developing robots for weeding crops on small (micro) farms; should cost under $5000. Uses AI and computer vision to identify weeds and crop diseases.\n\n\n\nArtificial Intelligence and Machine Learning\n\n\n\nGood thinking about how tech can build: infusing manufacturing with software and intelligence (IoT); enabling remote work; getting beyond the unicorn mindset.\n\n\n\nMicrosoft uses machine learning to inspect source code for security vulnerabilities. They claim they can identify high priority security bugs in new code 97% of the time.\n\n\n\nFacebook uses AI bots to simulate users for testing new social applications. They start up thousands of bots at a time to experiment with group dynamics, vulnerabilities, and privacy settings.\n\n\n\nGoogle Duo now uses AI to\u00a0 synthesize missing speech segments arising from lost packets in calls.\n\n\n\nThe new workplace\n\n\n\nSplunk announced Remote Work Insights, a network monitoring product for work-at-home companies. It has been criticized as employee surveillance; Splunk has responded that their intent is to monitor connectedness, not activity.\u00a0\u00a0\n\n\n\nLow-code automation is another aspect of the democratization of technology. The idea is to build tools that can be used by people without requiring a lot of programming experience. The target audiences are all over the place: from unskilled workers to managers, and even to programmers, where these tools will simplify product development.\u00a0\n\n\n\nProgramming\n\n\n\nMicrosoft announced IPE, a project that will contribute to the Linux kernel. IPE is for listing allowed binaries, and automatically checking signatures; it is intended for high security versions of Linux. But what\u2019s more important is that this is another sign that Microsoft has changed very deeply.\u00a0\n\n\n\nIBM is offering free COBOL training, in response to state governments\u2019 needs for more programmers to update unemployment systems.\n\n\n\nJupyterLab is now a full-fledged, web-based, multi-language IDE for data.Google is adding differentiable programming to the Swift programming language to simplify development of ML models. This means that their enhanced Swift language has primitives for computing the derivative/gradient of a function; in turn, this greatly simplifies key AI algorithms that involve gradient descent.\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/a7i2dB4x85I/"
 },
 {
  "title": "Four short links: 7 May 2020",
  "content": "\nSuper Bootable 64 \u2014 Super Mario 64 shipped before the SDK was finalised, and it had to be compiled with optimisations turned off. This meant the binary was easily reversed to source code, and now the unportable has been ported. This site probably won\u2019t last long, because DMCA, but it\u2019s technically a sweet feat. (via lobsters)\nIBM System/370 on a Raspberry Pi \u2014 I have been running a full IBM System/370 Mainframe on a $5 Raspberry Pi Zero for ~5 years. About 7 times faster System/370. Millions of lines of COBOL JCLs running flawless on a battery. Tested an entire bank\u2019s mainframe COBOL on it.\nsparks \u2014 A typeface for creating sparklines in text without code.\nAnnouncing the First Members of the Oversight Board \u2014 The Board will review whether content is consistent with Facebook and Instagram\u2019s policies and values, as well as a commitment to upholding freedom of expression within the framework of international norms of human rights. We will make decisions based on these principles, and the impact on users and society, without regard to Facebook\u2019s economic, political or reputational interests. Facebook must implement our decisions, unless implementation could violate the law. Impressive credentials. I\u2019d love to be a fly on the wall for their conversations, because this problem is Hard.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/02gVn4fsoAs/"
 },
 {
  "title": "Four short links: 6 May 2020",
  "content": "\nRaman Spectroscopy \u2014 Low Cost, High Performances, 100% Open Source Raman Spectrometer. [\u2026] We currently offer the spectrometer in a Starter Edition version designed for teaching Raman spectroscopy and we will soon release a Performance Edition version which achieves a tested 12 cm-1 resolution at low costs. Great to see this getting into the hands of hackers.\nFrames in Software Development \u2014 not the Lisp AI frames, but the semantic frames.  I always wondered why it isn\u2019t called \u201cproduct debt\u201d because product took the credit to get a feature faster and must pay back by investing the time to clean up. Technology is the bank that gave credit.\nPhoenix Framework \u2014 a web development framework written in Elixir which implements the server-side Model View Controller (MVC) pattern. I\u2019m reminded of ceej\u2019s \u201cWrite your own frameworks. You learn a lot. Your framework might solve a problem your ecosystem needs to have solved. By your tenth one, you know enough to write one worth wide adoption. Progress in our industry depends on all of us pushing it forward.\u201d\nDeleting Data Distributed Throughout Your Microservices Architecture \u2014 One solution is to think of data deletion not as an event, but as a process. At Twitter, we call this process \u201cerasure\u201d and coordinate data deletion between systems using an erasure pipeline. In this post, we\u2019ll discuss how to set up an erasure pipeline, including data discoverability, access, and processing. We\u2019ll also touch on common problems and how to ensure ongoing maintenance of an erasure pipeline.\nA Survey of Deep Learning for Scientific Discovery \u2014 The sheer breadth and diversity of different deep learning techniques makes it difficult to determine what scientific problems might be most amenable to these methods, or which specific combination of methods might offer the most promising first approach. In this survey, we focus on addressing this central issue, providing an overview of many widely used deep learning models, spanning visual, sequential and graph structured data, associated tasks and different training methods, along with techniques to use deep learning with less data and better interpret these complex models \u2014 two central considerations for many scientific use cases. We also include overviews of the full design process, implementation tips, and links to a plethora of tutorials, research summaries and open-sourced deep learning pipelines and pretrained models, developed by the community.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/JzKmpMWaB6M/"
 },
 {
  "title": "Four short links: 5 May 2020",
  "content": "\nLeaving Amazon (Tim Bray) \u2014 May 1st was my last day as a VP and Distinguished Engineer at Amazon Web Services, after five years and five months of rewarding fun. I quit in dismay at Amazon firing whistleblowers who were making noise about warehouse employees frightened of Covid-19.\nObservability is a Many-Splendoured Thing (Charity Majors) \u2014 if you can\u2019t predict all the questions you\u2019ll need to ask in advance, or if you don\u2019t know what you\u2019re looking for, then you\u2019re in o11y territory.\nUsing Neural Networks to Find Answers (Google) \u2014 deep learning to figure out how to turn natural language questions into queries over tables of data.\nRedesigning Trust: Blockchain Deployment Toolkit \u2014 World Economic Forum report on distributed ledger deployments, with advice. This toolkit provides tools, resources, and know-how to organizations undertaking blockchain projects. It was developed through lessons from and analysis of real projects, to help organizations embed best practices and avoid possible obstacles in deployment of distributed ledger technology\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/XxiXn3lntjQ/"
 },
 {
  "title": "On COBOL",
  "content": "\n\nHelping government through this crisis.\u00a0We\u2019re offering free access to O\u2019Reilly online learning to any individual who works for a US government agency to get the learning you need as your agency responds to unprecedented demand.\n\n\n\nFree .gov access >\n\n\n\n\n\nWe\u2019ve all seen that the world (well, governments, specifically state governments, to say nothing of the banks) is screaming for COBOL programmers\u2014a cry that goes up roughly every five years. We somehow muddle through the crisis at hand, then people forget that it was ever a problem. It\u2019s time we asked what the crisis really is, and why it keeps returning.\n\n\n\n\n\nCOBOL is one of the earliest programming languages; it was invented in 1960 and rose to prominence fairly quickly as a language that required minimal programming skills. (Real programmers wrote FORTRAN.) That\u2019s not how COBOL\u2019s inventors put it, but that is, to some extent, what they meant: a language that was supposed to be easy for programmers to learn, and that could also be understood by business people. Just look at what COBOL stands for: \u201cCommon Business-Oriented Language.\u201d A programming language for business.\n\n\n\nCOBOL\u2019s influence faded in the 1980s, and now, there are billions of lines of code in governments, banks, enterprises, and elsewhere performing essential business functions with nobody to maintain them. COBOL programmers have grown old and retired, and nobody came along afterward.\n\n\n\nWhat\u2019s the language like? I\u2019ve had occasion to look at COBOL code, and my reaction hasn\u2019t been what I expected. It doesn\u2019t look like any \u201cmodern\u201d language. But it\u2019s not a strange antique from the days before people knew how to design decent languages. COBOL is a well-thought-out domain-specific language. It\u2019s a business language that uses the language of businesspeople. Remember when Rubyists were proud that they could write statements that looked like idiomatic English? And that they could use metaprogramming to create domain-specific languages that used the vocabularies and concepts of different application domains? That was no small achievement. And COBOL did it 40-odd years earlier.\n\n\n\nLike other useful languages, COBOL never disappeared; but it has had surprisingly little influence on the development of computer languages, and that makes it look like it has died. In 10 Most(ly) Dead Influential Programming Languages, Hillel Wayne argues that COBOL had little influence on the development of programming languages because it came from the business community, and academics weren\u2019t interested in it\u2014for academics, it \u201cwasn\u2019t worth paying attention to.\u201d Who wants to write code that\u2019s readable by bankers and business people anyway? The allure of speaking a secret language that nobody else understood was always attractive to programmers.\n\n\n\nCOBOL nevertheless made a number of important innovations. It had a concept of records (like rows in a database), which was related to a concept of hierarchical structures, looking forward to C structs and perhaps even objects. And it has a report generator\u2014if that doesn\u2019t sound interesting, remember that one of the initial applications for Perl was report generation. And that another nearly forgotten early language, RPG, was invented purely to generate reports. Reports aren\u2019t glamorous, but they\u2019re important.\n\n\n\nSyntactically, COBOL asked a really good question: Why do we need to use the bastardized language of mathematics to move money around, by saying something like \u201ctotal = total + deposit\u201d? Wouldn\u2019t it be more natural to MOVE amounts from one account to another? Don\u2019t get too excited. MOVE sounds like a proto-transaction, but it isn\u2019t; it\u2019s just an assignment. However, if you\u2019re thinking about MOVE-ing money rather than assignment to a variable, those thoughts will lead you to atomic transactional operations sooner rather than later.\n\n\n\nOf course, there\u2019s a lot that COBOL doesn\u2019t offer. While COBOL has been updated with most of the features you\u2019d expect in a modern language (since 2002, it\u2019s even object-oriented), COBOL tends to lead to very awkward spaghetti code and monoliths. That\u2019s 1960s programming for you. GOTO was an essential part of every programming language (even C has a goto statement). Modularization wasn\u2019t well-understood, if it was understood at all. Libraries? The earliest versions of COBOL didn\u2019t have a standard library, let alone user-defined libraries. Web frameworks? You don\u2019t want to know. Microservices? Forget it.\n\n\n\nSo, where are we now, with our billions of lines of COBOL running the world\u2019s governments, and finances? I doubt there are many 1960s mainframes left, but there are plenty of emulations of 1960s mainframes running COBOL in the cloud much faster than the hardware it ran on initially. And that\u2019s one strategy I\u2019ve seen for maintaining COBOL: leave it as it is, run it on an emulator, wrap it up in a microservice written in some \u201cmodern\u201d language, and hope you never have to touch it. That buys time, but while \u201chope\u201d may solve the immediate problem, it\u2019s a poor long-term strategy.\n\n\n\nThe real problem isn\u2019t just the lack of programmers fluent in a language that is no longer popular. There are also cultural problems that need to be addressed\u2014and that have solutions that go beyond \u201ctrain up a new batch of COBOL programmers.\u201d First, one casualty of the \u201clanguage wars\u201d of the 90s and 00s is that we have an increasing number of programmers who identify with one language: they\u2019re JavaScript programmers, or Java programmers, or Python programmers, or Rubyists. Dave Thomas\u2019 and Andy Hunt\u2019s advice to learn a new programming language every year is just as valid as it was when they first wrote The Pragmatic Programmer; but it goes sadly unheeded. To be a good programmer, you need to expose yourself to new ideas, new ways of thinking about problems\u2014and, in the case of COBOL, old ideas. Programmers who can\u2019t be coaxed out of their comfort zone aren\u2019t going to learn COBOL; but in the long run, they\u2019ll prove to be less valuable, regardless of what modern language they know.\n\n\n\nSecond, COBOL programming requires an understanding of business programming. Regardless of the language, that\u2019s an increasingly rare specialty. How do you handle financial quantities, like dollars and cents? If you say \u201cfloating point,\u201d go to the back of the class. Roundoff errors will kill you. If you say \u201cuse integers, and divide by 100,\u201d that\u2019s not much better. The fundamental problem is that binary numbers are not good at representing decimal fractional values. But that\u2019s lore that most current programmers have never learned.\u00a0 (And we haven\u2019t even started thinking about currency conversions.)\n\n\n\nThird, engineering decisions made in the 1960s, 1970s, and even 1980s aren\u2019t the decisions we\u2019d make today. The engineering was certainly valid for its time, but modern engineers frequently don\u2019t understand why. I\u2019ve heard many contemporary programmers talk about the Y2K problem (representing years in the 1900s with two digits) as \u201ctechnical debt.\u201d That represents a misunderstanding of the issues the original programmers faced. In an environment when data was entered on 80-column punched cards, saving 2 characters was a Big Deal. In an environment where the largest computers had memories measured in Kilobytes (and a small number of K at that), saving 2 characters was a Big Deal. This isn\u2019t engineering that has to be replicated, but it does need to be understood.\u00a0\n\n\n\nFourth, old business software was monolithic\u2014and monolithic in a very deep sense. It tended to model forms that humans would fill out, and that couldn\u2019t be submitted until the form was complete. There\u2019s often no way to save your work, because\u2014why would you need to? You went to the unemployment office in person; you leave when you hand the application to the person behind the desk. An incomplete form goes into the wastebasket; why waste valuable storage on it? Putting a web interface in front of those monoliths leads to a predictable result: long, complex forms that can take hours to fill out, and that are close to unusable on the modern Web. In creating GetCalFresh, a streamlined application for food assistance in California, Code for America found that the old form took an hour to fill out\u2014but applicants often relied on public computers in libraries that didn\u2019t allow sessions longer than a half-hour. Since incomplete forms couldn\u2019t be saved, it was impossible for applicants to finish applying. Moving a COBOL application to an emulator, running it in the cloud, and hacking together a Web frontend isn\u2019t going to solve problems like this. The good news is that this is an opportunity to re-think your service and make it more effective. The bad news is that it\u2019s not a quick fix.\n\n\n\nSo, what\u2019s needed? Yes, we need more people who know and understand COBOL programs. There\u2019s a lot of old code that needs to be maintained, pure and simple. But it goes deeper. COBOL is just another programming language; if we\u2019re going to maintain (or replace) that software, we need programmers who understand the engineering decisions that made the software what it is. We also need engineers and managers who are willing to look at our current situation\u2014for example, the huge surge in unemployment applications\u2014and think beyond the short-term solution. What does it take to re-invent current systems, rather than just replace them? How can they become more human-centric? Can they be redesigned to match the way we live and work now? Putting a web front-end on a monolithic business process from the 1950s is the road to failure.\n\n\n\nThat\u2019s the new generation of COBOL programmers that we need: people to do the tedious, unglamorous work of re-inventing, re-engineering, and automating government applications, business applications, and much more. Reimagining these processes is creative work, but it requires a different kind of creativity from implementing a new website. I previously wrote about the distinction between blue- and white-collar programming. COBOL is very, very blue-collar. And very, very important. Every time the cry for COBOL programmers has gone up, we\u2019ve muddled through; this time, we should do something better.\n\n\n\nThe future of programming is re-understanding the past, and re-inventing it to meet our current challenges.\n\n\n\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/qjjGs15OegQ/"
 },
 {
  "title": "Four short links: 4 May 2020",
  "content": "\nPopcorn Linux \u2014 exploring how to improve the programmability of emerging heterogeneous hardware, in particular, those with Instruction Set Architecture (ISA)-diverse cores, from node-scale (e.g., Xeon/Xeon-Phi, ARM/x86, CPU/GPU/FPGAs) to rack-scale (e.g., Scale-out processors, Firebox, The Machine), in both native and virtualized settings.  Additionally, the project is exploring how to automatically compile/synthesize/execute code on ISA-heterogeneous hardware.\nIncorporating External Knowledge through Pre-training for Natural Language to Code Generation \u2014  In the second and third example, we can see that the baseline uses the wrong API calls, and sometimes \u201cmakes up\u201d APIs on its own (e.g. \u201crandom.savefig()\u201d). However, our approach\u2019s outputs, while not perfect, are much more successful at generating correct API calls that actually exist and make sense for the intent. The algorithm developers have made the system guess likely API calls as programmers do.\nUS Patent Office Rules that Artificial Intelligence Cannot be a Legal Inventor (Verge) \u2014 \u201cUnder current law, only natural persons may be named as an inventor in a patent application,\u201d the agency concluded. The ruling text has the arguments.\n\nDetecting Fake News for the New Coronavirus by Reasoning on the Covid-19 Ontology \u2014 interesting to see symbolic AI (reasoning over propositions) being useful here. In the context of the Covid-19 pandemic, many were quick to spread deceptive information. I investigate here how reasoning in Description Logics (DLs) can detect inconsistencies between trusted medical sources and not trusted ones. The not-trusted information comes in natural language (e.g. \u201cCovid-19 affects only the elderly\u201d). To automatically convert into DLs, I used the FRED converter. Reasoning in Description Logics is then performed with the Racer tool.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/NLMOWQkWi5U/"
 },
 {
  "title": "Four short links: 1 May 2020",
  "content": "\nTasmota \u2014 Alternative firmware for ESP8266 with easy configuration using webUI, OTA updates, automation using timers or rules, expandability and entirely local control over MQTT, HTTP, Serial or KNX.\nSelfie 2 Waifu \u2014 deep learning constructs an anime character from your photo. Paper for the underlying technique. (via @tkasasagi)\nThe Handbook of Cyber Wargames: Wargaming the 21st Century \u2014 Cyber wargaming combines two complex fields:  wargame design and cyber operations.  This handbook is full of examples of such manual games. It includes examples of: Network attack and defence exercises; Committee games; Company and state level games; Example of a Matrix Game; Analysing the cyber security space using Confrontation Analysis; Media Wars: The Battle to Dominate the Information Space; Attack Chain modelling. (via Nick Drage)\nOpenAI Jukebox \u2014 deep learning makes actual music in recognisable styles. There\u2019s a clever encoding of audio to make it learnable. It takes approximately 9 hours to fully render one minute of audio through our models. Yow.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/td60nlKZt60/"
 },
 {
  "title": "Four short links: 30 April 2020",
  "content": "\nTo Microservices and Back Again: Why Segment Went Back to a Monolith \u2014 microservices came with increased operational overhead and problems around code reuse. \u2026 If microservices are implemented incorrectly or used as a band-aid without addressing some of the root flaws in your system, you\u2019ll be unable to do new product development because you\u2019re drowning in the complexity.\nGNU poke \u2014 interactive editor for binary data. Not limited to editing basic entities such as bits and bytes, it provides a full-fledged procedural, interactive programming language designed to describe data structures and to operate on them. (via Kernel Recipes)\nBlender \u2014 Facebook open sourced their open-domain (\u201ccan talk about anything!\u201d) chatbot. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements.\nCopyLeft Conf 2020 Videos \u2014 the schedule has more info on each talk.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/-jpqQW9V448/"
 },
 {
  "title": "Four short links: 29 April 2020",
  "content": "\npodpaperscissors \u2014 From the classic \u201cprisoner\u2019s dilemma\u201d to more obscure co\u00f6rdination games, Pod Paper Scissors takes game theory out of the dry textbook and into the real world. \u2026 Each episode will feature different kinds of games and situations. Experts in a variety of fields will casually converse with the hosts about how the particular game discussed applies to their work. Some episodes feature original music inspired by the topic at hand. The podcast is hosted by game theorist Ben Klemens and science journalist and composer Liz Landau. (via Ben Klemens)\nVerification Handbook (3ed) \u2014 latest guide to investigating disinformation and media manipulation, covering identifying actors, investigating platforms, tracking ads, etc. (via Craig Silverman)\nRansomware Groups (Microsoft) \u2014 analysis of ransomware campaigns yields this report, which includes a great graphic taxonomy of ransomware payloads.\nBug Stories \u2014 great tales of bugs and bug-hunting from the past.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/TfggNzHCN9Y/"
 },
 {
  "title": "Four short links: 28 April 2020",
  "content": "\nLearning a Language \u2014 this list of questions facing anyone taking a new language for a test run just burns with truth. (Also: encouraging to see how many of these questions are answered by the Cookbook format)\nOpenVAS \u2014 Open Vulnerability Assessment Scanner, aka \u201cwhat a cheap external security assessment vendor will run and then mail you the report from.\u201d\nPaxos vs Raft: Have we Reached Consensus on Distributed Consensus? \u2014 We find that both Paxos and Raft take a very similar approach to distributed consensus, differing only in their approach to leader election. Most notably, Raft only allows servers with up-to-date logs to become leaders, whereas Paxos allows any server to be leader provided it then updates its log to ensure it is up-to-date. Raft\u2019s approach is surprisingly efficient given its simplicity as, unlike Paxos, it does not require log entries to be exchanged during leader election. We surmise that much of the understandability of Raft comes from the paper\u2019s clear presentation rather than being fundamental to the underlying algorithm being presented.\nGoogle Research Football \u2014 a novel Reinforcement Learning environment where agents aim to master the world\u2019s most popular sport\u2014football. Modeled after popular football video games, it provides a physics based 3D football simulation where agents control either one or all football players on their team, learn how to pass between them, and manage to overcome their opponent\u2019s defense in order to score goals.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/JgkxCAvjRqM/"
 },
 {
  "title": "Four short links: 27 April 2020",
  "content": "\nTeleforking a Process onto a Different Computer \u2014 a working proof of concept (I just don\u2019t replicate tricky things so that I could keep it simple, meaning it\u2019s just a fun tech demo you probably shouldn\u2019t use for anything real) of a telefork() function call that spawns a process on another machine and returns the instance ID.\nConsistency Maps \u2014 Jepsen analyses the safety properties of distributed systems\u2013most notably, identifying violations of consistency models. But what are consistency models? What phenomena do they allow? What kind of consistency does a given program really need? In this reference guide, we provide basic definitions, intuitive explanations, and theoretical underpinnings of various consistency models for engineers and academics alike.\nwasmachine \u2014 wasmachine is an implementation of the WebAssembly specification in a FPGA. It follows a sequential 6-steps design.\nExpert Twitter Only Goes So Far: Bring Back Blogs (Wired) \u2014 we\u2019re surrounded by opinion machines (because opinion is cheap to produce and make inflammatory, it\u2019s a natural fit for engagement-driven businesses), so it\u2019s nice to find knowledgeable people sharing their expertise. I see The Syllabus and newsletter systems like substack as part of the response to this dearth of high-alpha content. More please!\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/AEEWrXve-nY/"
 },
 {
  "title": "Four short links: 24 April 2020",
  "content": "\nThe Suddenly Remote Playbook \u2014 I just want to note that if you have to look after kids when you\u2019re supposed to be working, you\u2019re not working from home. Not everyone\u2019s getting a glorious introduction to the delights of working from home.\ntaichi \u2014 a programming language designed for high-performance computer graphics. It is deeply embedded in Python, and its just-in-time compiler offloads compute-intensive tasks to multi-core CPUs and massively parallel GPUs.\nThe Cost of Training NLP Models \u2014 We review the cost of training large-scale language models, and the drivers of these costs. The intended audience includes engineers and scientists budgeting their model-training experiments, as well as non-practitioners trying to make sense of the economics of modern-day Natural Language Processing (NLP).\nKilling Net Neutrality Did Not Save the Pandemic Internet \u2014 there\u2019s no evidence that European networks have fallen apart during the COVID-19 crisis. Or that any differences in performance have anything to do with deregulation or net neutrality. Netflix\u2019s decision to throttle back its bandwidth usage by 25% was done entirely pro-actively. There was no underlying network data provided by regulators to justify the move. It was just EU regulators being cautious (perhaps overly so). Indeed, similar steps have been taken here in the States. YouTube for example has downgraded video quality to conserve bandwidth. So has game platform Steam, which is slowing some game downloads. You can\u2019t selectively highlight the EU\u2019s efforts on this front then ignore the US ones because it supports your flimsy narrative. Well I guess you can, but you should be laughed at.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/iMWXW-TtFNM/"
 },
 {
  "title": "Four short links: 23 April 2020",
  "content": "\nMoloch \u2014 Large scale, open source, indexed packet capture and search.\n3Dify Instagram Photos \u2014 open source toolset for adding a 3d effect to photos on Instagram\u2019s web site. It uses 3d-photo-inpainting running in Colab (free GPU) and Cloud pubsub/storage for communication. A glimpse of the future: we could augment all our apps with deep learning-based services, but we still need to conquer paying for the GPUs and making it easy to use.\nxkcd 2295 \u2014 data science in a nutshell.\nSpotify Doesn\u2019t Use \u201cthe Spotify Model\u201d and Neither Should You (Jeremiah Lee) \u2014 I no longer work at Spotify, so I am sharing my experience to set the record straight. The Spotify squad model failed Spotify and it will fail your company too. EXTREMELY well-written. Full of killer points like Every responsibility a team cedes to increase its focus becomes a new cross-team dependency.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/Zostx6Dsl7M/"
 },
 {
  "title": "How data privacy leader Apple found itself in a data ethics catastrophe",
  "content": "Three months ago, Apple released a new credit card in partnership with Goldman Sachs that aimed to disrupt the highly regulated world of consumer finance. However, a well-known software developer tweeted that he was given 20x the credit line offered to his wife, despite the fact that they have been filing joint tax returns and live in a community property state. The story went viral on Twitter, and led to an official government investigation for bias. \n\n\n\nEven if Apple\u2014the privacy leader\u2014did not discriminate on gender, it experienced one of its worst product launches in recent history.\u00a0 \n\n\n\nApple\u2019s customer base and bankable style combined with Goldman\u2019s knowledge of the financial industry must have seemed like an unbeatable combination. Apple is a great producer of computer hardware, while Goldman knows finance and its complex rules backwards and forwards. If anyone could launch this product right, it would be these two companies.\n\n\n\nUltimately, Apple learned a critical lesson from this experience. User buy-in cannot end with compliance with rules. It requires ethics, constantly asking how to protect, fight for, and empower users, regardless of what the law says. These strategies contribute to perceptions of trust.\n\n\n\nTrust has to be earned, is easily lost, and is difficult to regain. \n\n\n\nCompliance and ethics\n\n\n\nCompliance is a simple concept: \u201cwe followed all applicable rules and regulations.\u201d Compliance minimizes the possibility of being fined and gives you a defense if you\u2019re taken to court. You can hire compliance experts to advise you, and lawyers to defend you. That said, compliance allows plenty of room for bad, unethical behavior. For example, payday lending businesses are no doubt compliant with the law, but many aren\u2019t models for good corporate citizenship.\n\n\n\nEthics is much more slippery. It\u2019s not about staying within legal boundaries; ethics is a discussion about what\u2019s right, not a set of rules. It\u2019s about living a \u201cgood\u201d life, acting in a way that allows you to live with yourself and others. There aren\u2019t simple standards and tests for ethical behavior, nor are you as likely to be called into court for acting unethically. But unethical behavior is likely to lose your customers\u2019 or business partners\u2019 trust; they will view your actions with suspicion. \n\n\n\nThe importance of ethics does not, however, mean companies should ignore compliance\n\n\n\nCompliance functions are powerful because legal violations result in clear financial costs. The European Union\u2019s General Data Protection Regulation (GDPR), for instance, imposes fines of up to 2%\u20134% of global annual revenue. This could mean millions, if not billions, of lost revenue. The era in which fines were merely a cost of doing business appears to be ending. Fines in the billions have been levied against Google and Facebook, and Practice Fusion (an electronic medical records company) has agreed to a $145 million settlement for using \u201cits EHR software to influence physician prescribing of opioid pain medications.\u201d\n\n\n\nBecause of its clear impact on the bottom line, compliance often reshapes business operations. For instance, financial companies are investing millions into using artificial intelligence to comply with anti-money laundering regulations or stricter data regulations.\n\n\n\nBecause compliance is so clear-cut, it is tempting to substitute compliance for ethics \n\n\n\nDon\u2019t do it.\u00a0 \n\n\n\nAs the Apple case illustrates, rule-following is not sufficient for trust-building. Laws are frequently a minimum standard; they set a low bar. As a privacy leader in the technology space, Apple knows this well and has benefited from a strong reputation as a data steward.\n\n\n\nFor one, the law often lags behind technology and user expectations. Organizations that simply follow the rules will be sideswiped by rapidly changing technology and user expectations. Case in point: the public hearings after the outrage over Facebook\u2019s Cambridge Analytica. Here, the public discovered that even highly experienced senators didn\u2019t fully understand key technologies, like Facebook, much less their potential harm on users. \n\n\n\nFurthermore, compliance-only companies will play a seemingly insurmountable game of \u201cwhack-a-mole\u201d as new data regulations pass around the world. New rules will catch these organizations off-guard, especially when they use emerging technologies and face ambiguous rules.\n\n\n\nFinally, investors from BlackStone to JP Morgan are beginning to prioritize environmental, social, and governance metrics\u2014like ethics\u2014into its definition of shareholder value. Legal compliance is increasingly inadequate for this powerful stakeholder.\n\n\n\nAs a result, to build trust, a company should lead with ethics\n\n\n\nIn our more global, diverse, and rapidly- changing world, ethics may be embodied by the \u201cplatinum rule\u201d: Do unto others as they would want done to them. One established field of ethics\u2014bioethics\u2014offers four principles that are related to the platinum rule: nonmaleficence, justice, autonomy, and beneficence. \n\n\n\nFor organizations that want to be guided by ethics, regardless of what the law says, these principles as essential tools for a purpose-driven mission: protecting (nonmaleficence), fighting for (justice), and empowering users and employees (autonomy and beneficence). \n\n\n\nAn ethics leader protects users and workers in its operations by using governance best practices.\u00a0\n\n\n\nBefore creating the product, it understands both the qualitative and quantitative contexts of key stakeholders, especially those who will be most impacted, identifying their needs and fears. When creating the product, it uses data protection by design, working with cross-functional roles like legal and privacy engineers to embed ethical principles into the lifecycle of the product and formalize data-sharing agreements. Before launching, it audits the product thoroughly and conducts scenario planning to understand potential ethical mishaps, such as perceived or real gender bias or human rights violations in its supply chain. After launching, its terms of service and collection methods are highly readable and enables even disaffected users to resolve issues delightfully. \n\n\n\nEthics leaders also fight for users and workers, who can be forgotten. These leaders may champion enforceable consumer protections in the first place, before a crisis erupts. With social movements, leaders fight powerful actors preying on vulnerable communities or the public at large\u2014and critically examines and ameliorates its own participation in systemic violence. As a result, instead of last-minute heroic efforts to change compromised operations, it\u2019s been iterating all along. \n\n\n\nFinally, ethics leaders empower their users and workers. With diverse communities and employees, they co-create new products that help improve basic needs and enable more, including the vulnerable, to increase their autonomy and their economic mobility. These entrepreneurial efforts validate new revenue streams and relationships while incubating next-generation workers who self-govern and push the company\u2019s mission forward. Employees voice their values and diversify their relationships. Alison Taylor, the Executive Director of Ethical Systems, argues that internal processes should \u201cimprove [workers\u2019] reasoning and creativity, instead of short-circuiting them.\u201d Enabling this is a culture of psychological safety and training to engage kindly with divergent ideas.\n\n\n\nThese purpose-led strategies boost employee performance and retention, drive deep customer loyalty, and carve legacies. \n\n\n\nTo be clear, Apple may be implementing at least some of these strategies already\u2014but perhaps not uniformly or transparently. For instance, Apple has implemented some provisions of the European Union\u2019s General Data Protection Regulation for all US residents\u2014not just EU and CA residents\u2014including the ability to access and edit data. This expensive move, which goes beyond strict legal requirements, was implemented even without public pressure. \n\n\n\nBut ethics strategies have major limitations leaders must address\n\n\n\nAs demonstrated by the waves of ethical \u201cprinciples\u201d released by Fortune 500 companies and commissions, ethics programs can be murky, dominated by a white, male, and Western interpretation. \n\n\n\nFurthermore, focusing purely on ethics gives companies an easy way to \u201cfree ride\u201d off social goodwill, but ultimately stay unaccountable, given the lack of external oversight over ethics programs. When companies substitute unaccountable data ethics principles for thoughtful engagement with the enforceable data regulation principles, users will be harmed.\n\n\n\nLong-term, without the ability to wave a $100 million fine with clear-cut requirements and lawyers trained to advocate for them internally, ethics leaders may face barriers to buy-in. Unlike their sales, marketing, or compliance counterparts, ethics programs do not directly add revenue or reduce costs. In recessions, these \u201csoft\u201d programs may be the first on the chopping block. \n\n\n\nAs a result of these factors, we will likely see a surge in ethics-washing: well-intentioned companies that talk ethics, but don\u2019t walk it. More will view these efforts as PR-driven ethics stunts, which don\u2019t deeply engage with actual ethical issues. If harmful business models do not change, ethics leaders will be fighting a losing battle. \n\n\n\nYet despite these tremendous barriers, leaders must weave ethics into their strategies\n\n\n\nEthics must be embraced by top leaders, who must fundamentally shift corporate governance, C-suite incentives, strategic roadmaps, and daily operations to empower stakeholders. Inconsistent or wishy-washy company behavior will severely harm, not build, trust.\n\n\n\nTo move beyond narrow interpretations of ethics, ethical leaders must engage with critiques\u2014like the Feminist Data Manifest-no. These push leaders to investigate and ameliorate power relations, marginalizing processes, and the history of injustice against vulnerable communities. \n\n\n\nSimilarly, leaders must engage with international human rights frameworks (IHRFs), such as the Universal Declaration of Human Rights and International Covenant on Economic, Social and Cultural Rights. While these have often been enforced against states (fighting, for instance, censorship, unfair trials, and torture), supporters nonetheless argue IHRFs afford a rich ecosystem of multilateral organizations, compliance approaches, shared language, and jurisprudence to help organizations balance human rights against competing interests, like innovation. \n\n\n\nTo gain more buy-in from top internal business leaders, ethics leaders can form coalitions with compliance, data, and even marketing departments. By leading programs with resources and measurable accountability, ethics leaders must articulate how ethics improves trust and loyalty. The effectiveness of such coalitions may explain the rise of chief ethics and compliance officers\u2014 as well as a host of new chief trust, social responsibility, citizenship, and data officers by technology leaders like Salesforce, Workday, and Unisys. Robert Smith, Director of Ethics and Compliance at InterContinental Hotels Group, agrees, arguing that these related teams should speak with \u201cone voice.\u201d \n\n\n\nTo further bolster support, leaders should consider participating and learning from new cross-sector coalitions. These include those focused (a) on specific technologies like AI, such as The Partnership on AI, (b) on specific industries, such as health (All-in), government (Civic Data Privacy Leaders Network), and cities (Cities Coalition for Digital Rights or the Right to the City Alliance); or (c) on a general set of emerging issues, such as IEEE, WEF, Metrolab, or Data Collaboratives Research Network. Due to the wide variety of community, academic, and nonprofit leaders, these coalitions also provide invaluable opportunities for leaders to diversify their networks and challenge their assumptions. \n\n\n\nWhile incorporating human rights and ethics into business strategies may be costly in the short run, over the long term, Paul Barrett, deputy director of New York University\u2019s Center for Business and Human Rights, argues that \u201ccompanies will benefit financially from operating humane, efficient supply chains and employing motivated workers proud of their jobs.\u201d\n\n\n\nUltimately, organizations that discard ethics may find themselves on the wrong side of history. They risk becoming the redlining banks that excluded communities of color from loans due to perceived financial risk, or the government agency that denied treatment to African Americans suffering from syphilis due to a desire to for innovative research, or the billion-dollar company whose planes killed 346 people, after placing \u201cundue\u201d pressure for safety approvals of new algorithms to improve take-off performance. \n\n\n\nIn the next decade, leaders\u2014from Apple to the next venture-financed startup\u2014 will use cutting-edge technologies in a fight for competitive advantage and better operations. But those that succeed in our history books protect, fight for, and empower their users, including the most vulnerable.\n\n\n\nLeaders must not give up.\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/zOB3ZaHRzgo/"
 },
 {
  "title": "Four short links: 22 April 2020",
  "content": "Posthog \u2014 open source product analytics. Into the Mainframe (Recurse) \u2014 the interviews with two mainframe programmers are a great reminder of how much things have changed. And how they haven\u2019t. For instance, later in my career I kept a weighted punching clown in my office. As programmers, we liked our users, but we also sort of hated them. They would make all these unreasonable requests, give us bad data, stuff like that. So all my staff could come by my office when they were mad at their users and punch the clown to feel better. It was fun.\u00a0I had two doors in my office, and one time some guy I\u2019d never seen before in my life walked into my office without knocking, punched the clown, and walked out the other door. Never saw him again.NetLogo \u2014 a multi-agent programmable modeling environment. For simulations/modeling.Things I Wished More Developers Knew About Databases (Jaana B. Dogan) \u2014 really good points, hard won from experience. You are lucky if 99.999% of the time network is not a problem.\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/8fB4w7v--aI/"
 },
 {
  "title": "Four short links: 21 April 2020",
  "content": "\nIt\u2019s Time to Learn (Scott Berkun) \u2014 a strong response to Marc Andreessen\u2019s It\u2019s Time to Build. It feels like we are in a disrupted time when anything is possible, and folks are wondering where the levers are to pull.\npygraphistry \u2014 a library to extract, transform, and visually explore big graphs.\nDesert Island Devops \u2014 a single-day virtual event, to be livestreamed on twitch.tv/oncallmemaybe on April 30th, 2020. All presentations will take place in the world of Animal Crossing: New Horizons.\nMSFT\u2019s Machine Learning-Powered Bug Sorting \u2014 Since 2001 Microsoft has collected 13 million work items and bugs. We used that data to develop a process and machine learning model that correctly distinguishes between security and non-security bugs 99 percent of the time and accurately identifies the critical, high priority security bugs, 97 percent of the time. This is an overview of how we did it. Part of the ongoing augmentation of developers by (ML-powered) software.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/LdaybsWcIt8/"
 },
 {
  "title": "Four short links: 20 April 2020",
  "content": "\nCastleDB \u2014 a structured static database [\u2026]. CastleDB looks like any spreadsheet editor, except that each sheet has a data model. [\u2026] stores both its data model and the data contained in the rows into an easily readable JSON file. [\u2026] allows efficient collaboration on data editing.\nMainframes Are Having a Moment (IEEE Spectrum) \u2014 Although many college and university computer science departments have cut back or dropped mainframe programming curriculum to focus on more modern languages and technologies, faculty and staff at others report an uptick in interest in Cobol and related classes. The increase began well before pandemic-related layoffs inundated state unemployment agency computer systems, causing government officials to put out the call for programmers who know Cobol to step in and help.\nswimOS \u2014 a complete, self-contained distributed software platform for building stateful, massively real-time streaming applications. swimOS implements a distributed microkernel, called the Swim Kernel, that is persistent without a database, reactive without a message broker, autonomous without a job manager, and which executes general purpose stateful applications without a separate app server.\nUsing a Self-Rewriting README Powered by GitHub Actions to Track TILs (Simon Willison) \u2014 writing down what you\u2019ve learned how to do keeps it fresh. I\u2019ve been doing it for years, as have other people \u2014 check out this person\u2019s astonishing collection.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/mi6oOgCeVnY/"
 },
 {
  "title": "Four short links: 17 April 2020",
  "content": "\nNebula \u2014open source distributed, scalable, lightning-fast graph database.\n\nCOBOL Programming Course \u2014 from the Open Mainframe Project.\nServerless Handbook \u2014 a resource teaching frontend engineers everything they need to know to dive into backend.\nNovel Annealing Processor Is the Best Ever at Solving Combinatorial Optimization Problems (IEEE Spectrum) \u2014 Dubbed STATICA (Stochastic Cellular Automata Annealer Architecture), the processor is designed to take on challenges such as portfolio, logistic, and traffic flow optimization when they are expressed in the form of Ising models.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/3qVGYfUcjio/"
 },
 {
  "title": "Four short links: 16 April 2020",
  "content": "\nKanboard \u2014 free and open source Trello-like Kanban boards.\nRemote Work Playbook \u2014 really useful advice on the actual mechanics of working remotely, not just which tools to use but how to use them. E.g., As an individual contributor, is there something you just did that you think a colleague would have to do at some point in the future, would this have been easier and faster if you had a document to consult? If your answer to both questions is yes, write documentation for the thing and store in a common place where your team can access. Notion is a great place to store this. You should also share the link in your instant communication channel so your colleagues are aware.\navatarify \u2014 deep fake technology used to give you avatars of your choice for use in Zoom and Skype.\npstress \u2014 Database concurrency and crash recovery testing tool. (via Percona blog)\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/U0I-RtlD5PE/"
 },
 {
  "title": "Four short links: 15 April 2020",
  "content": "\nCoding vs Programming (John Gruber) \u2014 I\u2019d noticed this linguistic change too. See also Engineering vs Programming vs Computer Science. Coding is shorter so it\u2019s probably gaining in popularity because shorter is easier to say and thus more convenient.\nmicrograd (Andre Karpathy) \u2014 A tiny Autograd engine (with a bite! :D). Implements backpropagation (reverse-mode autodiff) over a dynamically built DAG and a small neural networks library on top of it with a PyTorch-like API. Both are currently about 50 lines of code each.\nGame Cheating in Hardware \u2014 pcileech WebRadar is a browser based radar cheat for CS:GO that can be run on a different PC, connected to a PCIe card providing direct memory access to the target computer. It\u2019s like doping for e-sports. (via Luke Weston)\nRadar Trends to Watch: April 2020 \u2014 early weak signals of interesting developments in Ops & Infrastructure, Software Development, AI & ML, and Quantum Computing. Plus the unavoidable Coronavirus-driven changes.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/ZfAUNw01nEU/"
 },
 {
  "title": "Four short links: 14 April 2020",
  "content": "\nThe Science of Happiness \u2014 free enrolment in Berkeley\u2019s MOOC to teach positive psychology. Learn science-based principles and practices for a happy, meaningful life.\nThe New Business of AI (A16Z) \u2014 many AI companies have: Lower gross margins due to heavy cloud infrastructure usage and ongoing human support; Scaling challenges due to the thorny problem of edge cases; Weaker defensive moats due to the commoditization of AI models and challenges with data network effects.\nGroup Chat: The Best Way to Totally Stress Out Your Team \u2014 Group chat is like being in an all-day meeting, with random participants, and no agenda.\nHuman Standards Project \u2014 p2p-shared international and device manufacturer standards to assist diy ventilator and masks teams.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/K0z1jG0Q_GA/"
 },
 {
  "title": "Radar trends to watch: April 2020",
  "content": "Since early in March, technology news has been all Coronavirus, all the time. That\u2019s a trend we expect to continue through April and probably beyond. So let\u2019s start with Coronavirus news, and hope that we have something different for next month.\n\n\n\nCoronavirus\n\n\n\nThe Coronavirus pandemic is forcing reconsideration of how private data is used.\u00a0 Maciej Ceglowski\u2019s post \u201cWe need A Massive Surveillance Program\u201d is important, particularly since Maciej has a long history as a privacy advocate. At the same time, many other privacy advocates are saying, \u201cBe careful what you give up, because you won\u2019t get it back,\u201d including Edward Snowden.A number of organizations are using blockchains as a way of sharing coronavirus data. I don\u2019t think this will be the blockchain killer app (it\u2019s too specialized), but it might be the killer demo.\u00a0While the maker movement of a decade ago has died back, it\u2019s worth  noting that the coronavirus has spawned a lot of maker projects\u2014from facemasks to ventilators, and many things in between.\u00a024,000 Coronavirus research papers in one archive: Now the question is how researchers will use this archive effectively. There\u2019s really only one answer: automatic summarization and intelligent search using AI.\u00a0Apple has made biometrics on watches an essential feature. Other companies with smart watch products will be forced to follow\u2013especially since doctors are now replacing in-office visits with telemedicine. A lot of cultural change is needed before doctors will accept ambient data detection, but Coronavirus may force that change to happen.\n\n\n\nOperations and Infrastructure\n\n\n\nRolling updates for Kubernetes with Kublr: Rolling updates are an essential feature for groups that are practicing continuous deployment. There have been some hackish workarounds, but Kublr attempts to provide a real solution.AWS has a Linux-based operating system for containers called Bottlerocket. Bottlerocket\u2019s most important feature is that it streamlines the update process, making updating possible for container orchestrators.Monitoring production systems is an essential practice. m3 is an open source monitoring tool from Uber that is effective at huge scale. It is being commercialized by Chronosphere.\n\n\n\nSoftware Development\n\n\n\nMicrosoft buys npm: This certainly isn\u2019t Steve Ballmer\u2019s Microsoft. And, along with Microsoft\u2019s acquisition of GitHub, it makes Microsoft a dominant player in much of the open source movement.\u00a0Chrome has new tools to help develop for the visually impaired; they simulate what the page would look like with different vision problems. This is an important step forward for developers working on accessibility. Mozilla also has accessibility checking.\n\n\n\nArtificial Intelligence and Machine Learning\n\n\n\nRealtime transcription and translation with Google Translate: This feature is rolling out to Android now, and will be delivered to iOS later. There are lots of issues that they will have to think about\u2014for example, there are significant variations in Spanish from country to country\u2014but it\u2019s an impressive accomplishment for natural language technology.\u00a0We\u2019ve known for some time that AI-based image classification can be tricked. Researchers have shown that it is also possible to spoof LIDAR, which could have a big effect on the development of autonomous vehicles.\u00a0A data set is a world view. This isn\u2019t a new idea, but it\u2019s important. A must-read article.Facebook has developed a new system called Deep Entity Classification for detecting fake accounts. It\u2019s based on connection patterns between users and also seems to take advantage of machine-generated labeling.\u00a0\u00a0\n\n\n\nQuantum Computing\n\n\n\nTensorFlow Quantum integrates quantum computing into TensorFlow to jump-start research into machine learning on quantum computers. While TensorFlow does not directly support quantum computing, this makes it a tool for  simulations and prepares the way for supporting real quantum computers.Honeywell hasn\u2019t been part of the quantum computing picture so far, but at the beginning of March, it suddenly announced that it had built a quantum computer. They\u2019re claiming it will be twice as powerful as IBM\u2019s machine.\n\n\n\nOther\n\n\n\nThere is legislation in the US Senate that would have the effect of restricting encryption. While this is framed as a bill to combat child sexual abuse, it would have drastic effects on computer security of all kinds.\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/D3WiTNUnfCI/"
 },
 {
  "title": "Four short links: 13 April 2020",
  "content": "\nIntroduction to COBOL \u2014 a 1999 web site (!) with slides from a University of Limerick course. IBM will offer free (presumably more modern) training.\nzoombot \u2014 a highly advanced AI to handle Zoom calls.\nstorybook.js \u2014 open source toolkit and sandbox to build UI components in isolation so you can develop hard-to-reach states and edge cases.\ntic-80 \u2014 a fantasy computer for making, playing and sharing tiny games.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/P6lgHjTBq-c/"
 },
 {
  "title": "Four short links: 10 April 2020",
  "content": "\nFairMOT \u2014 one-shot multi-object tracking that remarkably outperforms the state-of-the-arts on the MOT challenge datasets at 30 FPS.\npipedream \u2014 IFTTT for coders.\nCompiler Explorer \u2014 an interactive tool that lets you type code in one window and see the results of its compilation in another window. Using the site should be pretty self-explanatory: by default the left hand pane is the source window and the right hand has the assembly output. (via Tim Westbrook)\nMOOM \u2014 move and zoom windows on a Mac. See also Magnet. (via Ben Gracewood and @kylehqcom)\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/Wo1OI-hrJWc/"
 },
 {
  "title": "Four short links: 9 April 2020",
  "content": "\nThe Fuzzy Edges of Character Encoding \u2014 the history, politics, and computational basics of text-based character encoding and digital representations of text, from Morse Code to ASCII to Unicode (and emoji), as well as alternative text encoding schemes. (via Everest Pipkin)\nAutoHotkey \u2014 an automation scripting language for Windows.\nThe Electronic Nose and its Applications: A Survey \u2014 very good summary of tech, limitations, and applications of \u201celectronic noses\u201d aka multiple chemical sensors plus some machine learning/statistics.\nfalsisign \u2014 Make it look like a PDF has been hand signed and scanned.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/JziWImi0zFw/"
 },
 {
  "title": "Four short links: 8 April 2020",
  "content": "\nSystem Design for Advanced Beginners \u2014 a friendly explanation of the what and why of systems, with acknowledgement of the real world like There are many tools out there, each with different strengths and weaknesses, and many ways to build a technology company. The real, honest reasons that we will make many of our technological choices will be \u201cwe chose X because Sara knows a lot about X\u201d and \u201cwe chose Y on the spur of the moment when it didn\u2019t seem like a big decision and we never found the time to re-evaluate.\u201d\nLozya \u2014 Teleconferencing with an RPG map. Walk around, talk to folks, have private conversations by huddling in a corner, or drop in on other conversations. Ideal for meetups!\nHammerspoon \u2014 desktop automation framework for macOS. It lets you write Lua scripts that hook into operating system functionality, allowing you to interact with the keyboard/mouse, windows, displays, filesystem, and much more. (via CSAIL\u2019s Missing Semester Potpourri)\nThe Hitchiker\u2019s Guide to Logical Verification (PDF) \u2014 book for a course, using Microsoft Research\u2019s Lean theorem prover.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/V8u8aZ2VPaE/"
 },
 {
  "title": "Four short links: 7 April 2020",
  "content": "\nlocust \u2014 open source load testing tool: define user behaviour with Python code, and swarm your system with millions of simultaneous users. (via @nzigel)\nBackground Matting \u2014 a method for creating a matte \u2013 the per-pixel foreground color and alpha \u2013 of a person by taking photos or videos in an everyday setting with a handheld camera. Most existing matting methods require a green screen background or a manually created trimap to produce a good matte. With source.\nLearning to See Through Obstructions \u2014 a learning-based approach for removing unwanted obstructions, such as window reflections, fence occlusions or raindrops, from a short sequence of images captured by a moving camera.\nCovid-19 Primer \u2014 algorithmic summaries of Covid-19 research, updated every 24h. (via Sean Gourley)\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/bh3WKpMqNYY/"
 },
 {
  "title": "Governance and Discovery",
  "content": "Data Governance sounds like a candidate for the most boring topic in technology: something dreamed up by middle-managers to add friction to data scientists\u2019 lives. The funny thing about governance, though, is that it\u2019s closely related to data discovery. And data discovery is neither dull nor additional friction; it\u2019s an exciting process that enables great data projects, ranging from traditional reporting to artificial intelligence and machine learning.\n\n\n\nThe idea of data governance originated in regulation and compliance. Not that long ago, data was a \u201cwild west\u201d: there were few rules and regulations about how it could be used or transferred, and most were industry-specific. That started to change with HIPAA, which covered medical data (though not much else). It changed in a big way with Europe\u2019s GDPR, which enacted stringent requirements for how data is used and how individuals control the use of data about themselves; it also provided significant penalties for organizations that disobeyed the rules. In the US, California enacted a data privacy law (CCPA) that is similar to GDPR in many ways, and other states are likely to follow.\n\n\n\nThe need for data governance is simple. People who work with data need to take those regulations into account. They need to track the data they have, where it came from, who was allowed to modify it, and how it was modified. If their dataset merges multiple data sources, they have to track those other sources. They need to be able to find and delete data on short notice if a customer requests it (for example, by exercising the GDPR\u2019s \u201cright to be forgotten\u201d). They need to know how the data was collected\u2014not just whether consent was requested and granted, but how their data sources were chosen. Who (or what) appears in the dataset? Are the data sources biased, and how might those biases affect results? And this requires a set of tools that is more sophisticated than dumping the data into a data warehouse or submerging it in a data lake. \n\n\n\nBut a funny thing happened. At the same time that companies had to prepare for increased regulation and scrutiny, they were also becoming more sophisticated about how they were using data. They were experimenting with machine learning and artificial intelligence; they were building models that could easily go astray (with embarrassing repercussions) if they were based on data that was out of date or erroneous. And they realized that their data science teams were spending an inordinate amount of time searching for data, which was frequently locked up in a departmental silo or submerged in a data swamp. They often compounded the time spent searching when they realized, after starting their analysis, the data they found was unusable. It was stale, incorrect, incomplete, badly described, or subject to any of a dizzying number of problems. If your data isn\u2019t trustworthy, the results you get from that data won\u2019t be trustworthy, either.\n\n\n\nWhat did the data scientists need? Tools to help them find relevant data, understand its schema, understand how it was collected, understand how and where it was used and whether they could trust it. What did the compliance experts need? Tools to help them find relevant data, understand its schema so they knew just what was included in the data, understand how the data was collected, how and where it was used, and whether they could trust it. Pretty soon, people realized that these were almost exactly the same problem.\n\n\n\nThe problem boils down to managing metadata\u2014the data about the data, the data that describes the data. Companies need to manage their metadata so they know what their data means: how it was collected, how the data is represented, how the columns in a table are defined, when the data was updated, and even how frequently it is accessed. Data that hasn\u2019t been used for a few years probably hasn\u2019t been used for a good reason. Companies also need to track restrictions on data\u2019s use, who is allowed to access it, who is allowed to change it, and much more. Datasheets for Datasets describes some of the metadata that has to be tracked to manage data effectively. Managing this metadata has often been handled by a \u201cdata steward\u201d; but as data scales, delegating metadata management to a single person becomes ineffective. It\u2019s impossible to keep up with all the data flowing into an organization\u2014even a small one.\n\n\n\nAnd that\u2019s what makes data governance interesting. It\u2019s not just a requirement that\u2019s imposed by external regulators. It\u2019s about the process of understanding what data you have, what that data means, and how to use it. And it\u2019s surprising (well, not to any data scientist) how few companies actually understand the data they have, and what they can do with it. And once you understand your data\u2014what you have, what it means, where it came from\u2014you\u2019re finally in a position to use it effectively.\n\n\n\nHow does this look in practice? The open source project Amundsen was started to enable data discovery at Lyft. It enables data scientists to search for data in Lyft\u2019s \u201cdata lake,\u201d and implements something like Google\u2019s PageRank algorithm to rank relevant data sources. It also tracks who has accessed the data, how often, and when; data that is used frequently is more likely to be well-maintained. Although Amundsen was built to solve a supposedly different problem, it has also become a tool for data governance. It\u2019s really about metadata management, and that\u2019s at the heart of data governance.\u00a0 \n\n\n\nIt\u2019s also important to think about what metadata management tools like Amundsen don\u2019t provide. Amundsen tracks data access, so there\u2019s a virtual \u201cpaper trail\u201d about how data was used, but it doesn\u2019t implement any kind of access control. It won\u2019t prevent someone from accessing data they shouldn\u2019t; it just lets you document what happened after the fact. It\u2019s better at tracking down a violation than preventing one. It also doesn\u2019t track data lineage (at least, not yet), although users can add metadata about how data is modified and remixed. So it\u2019s not a complete solution\u2014but it\u2019s a step toward a solution. \n\n\n\nGoing beyond metadata management, many data governance platforms are designed to enforce data access policies. They go beyond leaving a \u201cpaper trail\u201d by restricting data access to those who have appropriate credentials, even on a record-by-record basis. They can also track data lineage, build data catalogs, and search for relevant data. Most of the commercial tools provide explicit support for regulatory compliance, such as GDPR and CPPA.\u00a0 \n\n\n\nRegardless of the tools, data governance and data discovery go together. You can\u2019t use your data if you can\u2019t find it. You can\u2019t use your data if you don\u2019t even know what data you have. And you\u2019re still at risk of data breaches, legal liability, and violating customer\u2019s trust, even if\u2014especially if\u2014you don\u2019t know what data you have. Data governance starts with metadata. And once you understand that, you understand that by requiring you to manage your metadata, data governance is an enabler, not a hindrance. That\u2019s when you can really think productively about how to use your data\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/bDh1ARjfuqw/"
 },
 {
  "title": "Four short links: 6 April 2020",
  "content": "\nRufus \u2014 Create bootable USB drives the easy way.\nImproving Audio Quality in Duo with WaveNetEQ \u2014 Google filling in missing packets in voice calls using deep learning.\nCRN++ \u2014 language for programming deterministic (mass-action) chemical kinetics to perform computation.\nCrafting Crafting Interpreters \u2014 story behind the writing of the Crafting Interpreters book.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/4PONL-GlTVk/"
 },
 {
  "title": "Four short links: 3 April 2020",
  "content": "\nThe Zero Trust Learning Curve (Palo Alto Networks) \u2014 don\u2019t learn with the Crown Jewels. The trouble with starting with the most sensitive protect surfaces is that they\u2019re often too fragile and many people don\u2019t know how they work. Starting there with Zero Trust frequently results in failures. Too often, when this happens, organizations blame these failures on Zero Trust. In fact, the problem is that no one in the organization has experience building Zero Trust environments.\nSoftware Engineering Advice from Building Large-Scale Distributed Systems (Jeff Dean) \u2014 slide deck from a Stanford talk he gave.\ngorkiy \u2014 decompilation of Russia\u2019s COVID-19 person tracker.\nOpen Source, Experimental, and Tiny Tools Roundup \u2014 tons of tools for games, graphics, sounds, live coding, zines, and more.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/oihNdyY6L8c/"
 },
 {
  "title": "Four short links: 2 April 2020",
  "content": "\nImperial College\u2019s COVID19 Model \u2014 in github, in R, MIT-licensed. This repository has code for replication purposes. The bleeding edge code and advancements are done in a private repository.\nReadings on Time \u2014 I bumped on this idea while reading Alan Kay\u2019s writing about making the difference between mutable and immutable data \u201cmoot\u201d in the context of FP vs. OOP by bringing in the concept of managed time. Since then I have been on the look out for material that helps develop my understanding on this subject. It is a fertile area with a lot of open problems for research and bringing back the fruits of these labour as an interactive system will unlock new pathways in computing. Here I present a collection of some of the resources that have helped me in charting my journey.\nDouyin Suspending Cantonese Livestreamers \u2014 you might dislike Facebook\u2019s privacy settings but they don\u2019t tell people they can\u2019t speak their own language.\nvim cubed \u2014 awful to use, but it looks GREAT.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/TJN5y_x03mc/"
 },
 {
  "title": "Four short links: 1 April 2020",
  "content": "Replaying Traffic to Test Proprietary Systems \u2014 using Wiresham to replay traffic to test blackbox proprietary systems.Outlaw Innovations \u2014 This paper will explore how the often illegal activities of hackers (in the original usage of the term to refer to individuals who modify computer hardware and software) may produce valuable innovations. It will explore how these innovations, termed Outlaw Innovations, may be appropriated by firms and provide case studies where this has taken place. The paper will seek to locate this phenomenon in the existing innovation literature, and explore the implications for firm innovation processes.Testing TikTok Algorithm Theories \u2014 I\u2019m fascinated by people reverse-engineering algorithms like this. It\u2019s kinda like people trying to figure out what the gods want.\nriftty \u2014 Terminal emulator meant for use with the Oculus Rift headseat. I used to dream of lying in bed with a split keyboard and a headset, never needing to even get vertical. Now I\u2019m in my 40s, I acknowledge that removing the only movement I get in my working life (walking to the desk and sitting) would probably a step in the wrong direction. But still, this feels nerd-important.\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/4lXCER6WqOc/"
 },
 {
  "title": "Four short links: 31 March 2020",
  "content": "\nMedtronic Releases Ventilator Designs \u2014 not open source, as the license is a limited-time limited-purpose license that retains rights. I imagine some corporate lawyers have done some frantic Googling for open meditech licensing clauses.\ndolt \u2014 version history for tabular data. Compare to sno, which is version control for geospatial and tabular data.\nToast UI Editor \u2014 extensible WYSIWYG Markdown editor.\nHow to be Curious Instead of Contrarian \u2014 it\u2019s about Coronavirus/Covid-19 but could apply equally well to any topic. 1) Care about the answer to a question; 2) Post a question and propose a research design that could answer it; 3) Use failures of your predictions to revise your mode; 4) Form meaningful prior beliefs with a thorough literature review; 5) Don\u2019t form strong prior beliefs based on cherry-picked data; 6) Be specific and concrete about your theory; 7) Choose enough cases to actually test your theory; 8) Convey uncertainty with specificity not doublespeak.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/rWYuEOCk7ng/"
 },
 {
  "title": "What you need to know about product management for AI",
  "content": "If you\u2019re already a software product manager (PM), you have a head start on becoming a PM for artificial intelligence (AI) or machine learning (ML). You already know the game and how it is played: you\u2019re the coordinator who ties everything together, from the developers and designers to the executives. You\u2019re responsible for the design, the product-market fit, and ultimately for getting the product out the door. But there\u2019s a host of new challenges when it comes to managing AI projects: more unknowns, non-deterministic outcomes, new infrastructures, new processes and new tools. A lot to learn, but worthwhile to access the unique and special value AI can create in the product space.\nWhether you manage customer-facing AI products, or internal AI tools, you will need to ensure your projects are in sync with your business. This means that the AI products you build align with your existing business plans and strategies (or that your products are driving change in those plans and strategies), that they are delivering value to the business, and that they are delivered on time. A PM for AI needs to do everything a traditional PM does, but they also need an operational understanding of machine learning software development along with a realistic view of its capabilities and limitations.\nWhy AI software development is different\nAI products are automated systems that collect and learn from data to make user-facing decisions. Pragmatically, machine learning is the part of AI that \u201cworks\u201d: algorithms and techniques that you can implement now in real products. We won\u2019t go into the mathematics or engineering of modern machine learning here. All you need to know for now is that machine learning uses statistical techniques to give computer systems the ability to \u201clearn\u201d by being trained on existing data. After training, the system can make predictions (or deliver other results) based on data it hasn\u2019t seen before.\nAI systems differ from traditional software in many ways, but the biggest difference is that machine learning shifts engineering from a deterministic process to a probabilistic one. Instead of writing code with hard-coded algorithms and rules that always behave in a predictable manner, ML engineers collect a large number of examples of input and output pairs and use them as training data for their models.\nFor example, if engineers are training a neural network, then this data teaches the network to approximate a function that behaves similarly to the pairs they pass through it. In the best case scenario, the trained neural network accurately represents the underlying phenomenon of interest and produces the correct output even when presented with new input data the model didn\u2019t see during training. For machine learning systems used in consumer internet companies, models are often continuously retrained many times a day using billions of entirely new input-output pairs.\nMachine learning adds uncertainty\nWith machine learning, we often get a system that is statistically more accurate than simpler techniques, but with the tradeoff that some small percentage of model predictions will always be incorrect, sometimes in ways that are hard to understand.\nThis shift requires a fundamental change in your software engineering practice. The same neural network code trained with seemingly similar datasets of input and output pairs can give entirely different results. The model outputs produced by the same code will vary with changes to things like the size of the training data (number of labeled examples), network training parameters, and training run time. This has serious implications for software testing, versioning, deployment, and other core development processes.\nFor any given input, the same program won\u2019t necessarily produce the same output; the output depends entirely on how the model was trained. Make changes to the training data, repeat the training process with the same code, and you\u2019ll get different output predictions from your model. Maybe the differences will be subtle, maybe they\u2019ll be substantial, but they\u2019ll be different.\nThe model is produced by code, but it isn\u2019t code; it\u2019s an artifact of the code and the training data. That data is never as stable as we\u2019d like to think. As your user base grows, the demographics and behavior of the user population in production shift away from your initial training data, which was based on early adopters. Models also become stale and outdated over time. To make things even more challenging, the real world adapts to your model\u2019s predictions and decisions. A model for detecting fraud will make some kinds of fraud harder to commit\u2013and bad actors will react by inventing new kinds of fraud, invalidating the original model. Models within AI products change the same world they try to predict.\nUnderneath this uncertainty lies further uncertainty in the development process itself. It\u2019s hard to predict how long an AI project will take. Predicting development time is hard enough for traditional software, but at least we can make some general guesses based on past experience. We know what \u201cprogress\u201d means. With AI, you often don\u2019t know what\u2019s going to happen until you try it. It isn\u2019t uncommon to spend weeks or even months before you find something that works and improves model accuracy from 70% to 74%. It\u2019s hard to tell whether the biggest model improvement will come from better neural network design, input features, or training data. You often can\u2019t tell a manager that the model will be finished next week or next month; your next try may be the one that works, or you may be frustrated for weeks. You frequently don\u2019t know whether something is feasible until you do the experiment.\nAI product estimation strategies\nPlanning and estimation are difficult for AI products because it is rare to find two real-world systems where the training data and algorithms applied are the same.\nImagine you are a data scientist at Disney. Your division is starting a new video streaming service and you\u2019re tasked with building a system to recommend movies. You might establish a baseline by replicating collaborative filtering models published by teams that built recommenders for MovieLens, Netflix, and Amazon. There may even be someone on your team who built a personalized video recommender before and can help scope and estimate the project requirements using that past experience as a point of reference.\nIn this scenario, your Disney team appears to be solving a problem similar to the early Netflix Prize recommendation problem. You have a highly curated catalog with a small number of professionally produced movies and TV series, and need to recommend those items to users based on their interests and viewing habits. Your team also needs to solve a cold start problem so you can recommend movies before the system begins collecting user feedback data (typically solved by using contextual topic-based or popularity-based recommendations), but once you gather explicit user ratings and video viewing data, you should be able to build a reasonable system. It may even be faster to launch this new recommender system, because the Disney data team has access to published research describing what worked for other teams.\nBut this is a best-case scenario, and it\u2019s not typical. What if instead of a narrow, curated video catalog, you were building a recommender system for a consumer video app, where anyone could create and upload user-generated content (UGC)? You might have millions of short videos, with user ratings and limited metadata about the creators or content. Social and trending signals in this network will be important, and controlling spam and abuse will be a challenge. It may even be necessary to do image or video analysis to make content-based recommendations, detect fraud, or reject content that violates your rules (for example, live shooter videos). You could still begin by shipping a simple cold-start recommender system, but it will take you much longer to build and iterate on your model to achieve the level of accuracy the business expects. You will likely encounter many challenges training your recommender with large amounts of constantly changing UGC and conflicting objectives.\nThese issues may be unexpected for teams that aren\u2019t familiar with developing machine learning systems trained on user-generated content. If you ignore these complications during planning and assume your system will behave similarly to the original recommenders at Netflix, the project will end up significantly behind schedule, and may have serious abuse problems that Netflix didn\u2019t face. In each of these examples, the machine learning problem faced by the business was similar (recommend movies to users), but the required approach ended up being very different based on subtle differences in the data and product design.\nPredicting development time becomes even more difficult when you apply an algorithm successfully used in one domain to a different problem. Consider using the Netflix collaborative filtering algorithm to recommend jobs to job seekers. On the surface, these problems seem similar: we have a dataset of items (jobs) and users (job seekers), so, in theory, we could use a job seeker\u2019s history of saved jobs or job applications to recommend similar new jobs. Complications arise when you consider the nuances of recruiting data and job applications. Features like geography and job seniority are critical to getting a good match. Job postings have a much shorter relevant lifetime than movies, so content-based features and metadata about the company, skills, and education requirements will be more important in this case. Job recommendations also include additional algorithmic and regulatory challenges related to diversity, bias, and fairness that are not encountered in movie recommendations.\nThe point isn\u2019t that estimating AI projects is intractably hard; it\u2019s that you aren\u2019t likely to succeed if you expect an AI project to behave like a traditional software project. There are strategies for dealing with all of this uncertainty\u2013starting with the proverb from the early days of Agile: \u201cdo the simplest thing that could possibly work.\u201d You don\u2019t always need to start with a complex neural network; a simple regression (or even simpler, an average) might be enough to get your project off the ground. In some cases, that simple model may be all you ever need. The biggest problems arise from taking shortcuts and assuming that a machine learning model that works for one application will perform well in a different context without looking at the underlying data.\nOrganizational prerequisites for AI at scale\nParticularly at a company that\u2019s new to AI, part of an AI product manager\u2019s job is helping the organization build the culture it needs to succeed with AI. Because it\u2019s so different from traditional software development, where the risks are more or less well-known and predictable, AI rewards people and companies that are willing to take intelligent risks, and that have (or can develop) an experimental culture. As Jeff Bezos has said, \u201cIf you only do things where you know the answer in advance, your company goes away.\u201d\nNo company wants to dry up and go away; and at least if you follow the media buzz, machine learning gives companies real competitive advantages in prediction, planning, sales, and almost every aspect of their business. If machine learning is so amazing, why hasn\u2019t every company applied it and reinvented itself?\nEven simple machine learning projects can be difficult, and managing these projects in a real business is much harder than most people realize; that\u2019s why VentureBeat claims 87% of machine learning products never make it into production, and Harvard Business Review says that \u201cThe first wave of corporate AI is bound to fail.\u201d Machine learning is not fairy dust you can sprinkle on your existing product. You can\u2019t just plug in off-the-shelf cloud APIs that will magically make your product intelligent. Machine learning requires a complete rethinking; your products and your workflows are likely to change in fundamental ways. Product managers for AI need to lead that rethinking.\nVentureBeat discusses two reasons for failure: management that believes you can solve problems by throwing money at them (whether that means hiring more, or better, developers), and data that is locked away into silos, where the people building your ML applications can\u2019t get it. These are fundamentally cultural problems. You need to understand that many solutions can\u2019t be bought (yet), that AI products require collaboration between teams, that data silos stand in the way of success, and that the best remedy for failure is picking yourself up and trying again. (To be clear, we are not saying that data can or should be used indiscriminately, without concern for legal compliance, customer privacy, bias, and other ethical issues.)\nThe need for an experimental culture implies that machine learning is currently better suited to the consumer space than it is to enterprise companies. For enterprise products, requirements often come from a small number of vocal customers with large accounts. It\u2019s difficult to be experimental when your business is built on long-term relationships with customers who often dictate what they want. Measurement, tracking, and logging is less of a priority in enterprise software. An enterprise company like Oracle has a lot of customers, but Oracle\u2019s customer base is dwarfed by Amazon\u2019s or Walmart\u2019s. Consumer product management is typically more bottom-up, driven by large volumes of user feedback and usage tracking data. Many consumer internet companies invest heavily in analytics infrastructure, instrumenting their online product experience to measure and improve user retention. It turns out that type of data infrastructure is also the foundation needed for building AI products.\nThe ability to make decisions based on data analytics is a prerequisite for an \u201cexperimental culture.\u201d This was the path taken by companies like Google, Facebook, and LinkedIn, which were driven by analytics from the beginning. At measurement-obsessed companies, every part of their product experience is quantified and adjusted to optimize user experience.\nThese companies eventually moved beyond using data to inform product design decisions. They have deployed machine learning at scale to recommend movies and friends, personalize ads, and deliver search results. Their user agreements allow them to use data to improve their products. They\u2019ve built the infrastructure needed to collect, manage, and analyze their data, and deploy AI products that can automatically make user-facing decisions in real time. By putting these pieces together, these companies created an environment where machine learning discoveries and innovation in AI are an integral property of their culture.\nYou are unlikely to succeed at AI if you haven\u2019t laid a proper foundation for it. That foundation means that you have already shifted the culture and data infrastructure of your company. In \u201cThe AI Hierarchy of Needs,\u201d Monica Rogati argues that you can build an AI capability only after you\u2019ve built a solid data infrastructure, including data collection, data storage, data pipelines, data preparation, and traditional analytics. If you can\u2019t walk, you\u2019re unlikely to run. Just as AI product managers need to help build a culture in which they can succeed, they need to help define and build the infrastructure that will allow an organization to walk, and then to run.\nIf you\u2019re just learning to walk, there are ways to speed up your progress. Although machine learning projects differ in subtle ways from traditional projects, they tend to require similar infrastructure, similar data collection processes, and similar developer habits. A relatively narrow project, like an intelligent search interface for your product, will require you to develop a lot of the basics, starting with the ability to acquire, clean, store, and analyze data. You\u2019ll become familiar with the problems that real-world data presents. You\u2019ll have to build the infrastructure that data projects require. Most important, you\u2019ll start building relationships with other teams\u2013and those relationships will become crucial when you tackle bigger projects.\nThe prospect of taking on a costly data infrastructure project is daunting. If your company is starting out on this path, it\u2019s important to recognize that there are now widely available open source tools and commercial platforms that can power this foundation for you. According to Lukas Biewald, founder of Figure Eight and Weights & Biases: \u201cBig companies should avoid building their own machine learning infrastructure. Almost every tech company I talk to is building their own custom machine learning stack and has a team that\u2019s way too excited about doing this.\u201d\nIf you are still figuring out your analytics strategy, you are fighting the last war. That doesn\u2019t mean you shouldn\u2019t be thinking about AI, but it\u2019s a goal, not the next step. Start with a simple project, build your infrastructure, learn how to use your data effectively, build relationships within the organization, then make the leap.\nIdentifying \u201cviable\u201d machine learning problems\nAny product manager is part of the team that determines what product to build. If you are just starting out with AI, that decision is especially important\u2013and difficult. The stakes are high\u2013and you can be pardoned if you\u2019re uncomfortable with ideas that are expensive and have an uncertain probability of success. Product managers are more comfortable with roadmaps that can get to market value in the next 12 months, and costs that can be kept to a minimum. AI doesn\u2019t fit that model. An AI pilot project, even one that sounds simple, probably won\u2019t be something you can demo quickly. You will struggle to make the case to invest in research upfront.\nTherefore, you need to pay particular attention to defining a \u201cminimum viable product\u201d (MVP). How do you find an MVP, with the stress on both \u201cminimum\u201d and \u201cviable\u201d? What features should be deferred to later versions, and what belongs in the initial release? A demo, or even a first release, can be based on heuristics or simple models (linear regression, or even averages). Having something you can demo takes some of the pressure off your machine learning team. But you still need to answer the question: how do you tell the difference between technology you can productize now, and that which will be viable in an uncertain time frame? Most interesting things in AI are on the cutting edge of what we can do in engineering, and that makes them unpredictable: you don\u2019t know when the engineering team will have the insight needed to make the product work. Those cutting-edge ideas are also attractive, both to managers who don\u2019t understand the risks and to developers who want to try something that\u2019s really challenging. And you, as the product manager, are caught between them.\nEffective product managers for AI know the difference between easy, hard, and impossible problems. A good example of a problem that has been hard or impossible until recently is generative text summarization. It seems like it should be within reach of our current machine learning algorithms, but in practice, accurately summarizing arbitrary text is still beyond the state of the art. You can generate text that, at first glance, appears to be written by a human, but upon closer inspection, you will often find it filled with factual and grammatical errors unacceptable in most business applications. This the \u201cart of the possible,\u201d an intuition for what is and isn\u2019t feasible. It\u2019s an intuition that you can learn through experience\u2013and it\u2019s why understanding your failures is at least as important as understanding your successes.\nFor AI products, one important part of being \u201cfeasible\u201d is being precisely defined. As Jeremy Jordan says, \u201cA problem well-defined is half solved.\u201d It\u2019s easy to look at the many successes of AI over the past few years and think that there\u2019s some magic, but there really isn\u2019t. If you can state what you want to accomplish very precisely, and break that down into even simpler problems, you\u2019re off to a good start. Jordan has some good advice: start by solving the problem yourself, by hand. If you want to help customers organize pictures on their phones, spend some time on your phone, organizing pictures. Interview actual customers to see what they want. Build a prototype they can try with real data. Above all, don\u2019t think that \u201cwe want to help customers organize pictures\u201d is a sufficient problem statement. It isn\u2019t; you\u2019ve got to go into much more detail about who your customers are, how they want to organize their pictures, what kinds of pictures they\u2019re likely to have, how they want to search, and more.\nAnother good proxy for identifying \u201cviable\u201d machine learning problems is to see how quickly you can construct a labeled benchmark dataset along with clear, narrowly defined accuracy goals for your ML algorithm. Data labeling ease is a good proxy for whether machine learning is cost effective. If you can build data labeling into normal user activities within your product (for example, flagging spam emails), then you have a shot at gathering enough input-output pairs to train your model. Otherwise, you will burn money paying external services for labeled data, and that up-front cost\u2013before you can do your first demo\u2013can easily be the most expensive part of the project. Without large amounts of good raw and labeled training data, solving most AI problems is not possible.\nEven with good training data and a clear objective metric, it can be difficult to reach accuracy levels sufficient to satisfy end users or upper management. When you\u2019re planning a product, it\u2019s important to have a gut feel for what error rates are achievable and what aren\u2019t, and what error rates are acceptable for your application. Product recommendations are easy; nobody is injured if you recommend products that your customers don\u2019t want, though you won\u2019t see much ROI. Fraud detection is riskier; you\u2019re working with real money, and errors show up in your bottom line. Autonomous vehicles are a different matter; if you\u2019re building an autonomous vehicle, you need AI that is close to perfect. (And perfect will never be achievable.) That kind of difference has a tremendous effect on how you structure the development process.\nWork on things that matter to your business\nThe most important advice we can give is to make sure you work on AI products that matter to the business. It\u2019s entirely too easy to define a problem, spend three to six months solving it, and then find out the solution works, but nobody cares; it doesn\u2019t make a difference to the business. One of a product manager\u2019s most important jobs is ensuring that the team is solving a problem that\u2019s worth solving.\nIf you have a good data team and an intuitive understanding of your company\u2019s data, there should be no shortage of ideas around how to improve your product. You will probably have more ideas than you can possibly use\u2013so how do you prioritize the list of machine learning projects? How do you select what to work on? What delivers the greatest ROI? Shipping any machine learning system requires a huge mountain of organizational and data engineering effort, so the ultimate payoff needs to match that investment.\nThe buzz around AI has encouraged many people to think that AI can suddenly double or triple your profitability. That\u2019s unlikely to be true\u2013but what is likely? A product manager needs to be realistic about expectations. You shouldn\u2019t over-promise, and you shouldn\u2019t under-deliver. But neither should you under-promise: while simple products might help you to get started, you want to show upper management you can move the needle significantly. If the needle doesn\u2019t move, you will undermine your team. If a product is feasible, if it\u2019s something customers want, if you can get realistic error rates, and if you understand the development flows, you still have to ask whether it\u2019s the best investment of time and resources. Is there another product that will generate a greater return more quickly?\nTo make these judgements, an AI product manager needs to understand the company\u2019s data inside and out. That includes the ability to do your own analysis, to run SQL queries, to develop metrics, and to build dashboards. If you don\u2019t understand your data intimately, you will have trouble knowing what\u2019s feasible and what isn\u2019t. You will have trouble understanding problems with data quality\u2013you should know in your bones why 80% of a data scientist\u2019s time is spent cleaning data. Without this data familiarity, you will have trouble spotting ethical problems that arise from biased or insufficient data. If you can\u2019t define the right metrics to monitor, you won\u2019t know whether or not your product is successful, nor will you know when your model performance has degraded (as it almost inevitably will).\nEven if a product is feasible, that\u2019s not the same as product-market fit. Is the product something that customers need? Will it help a small segment of customers or will it increase the most important metric for the majority of your users? Too many companies focus on building something cool without thinking about whether anyone really cares. Customers want you to solve their problems; they don\u2019t care what kind of neural network you\u2019re using. You may discover that you don\u2019t need AI at all, and that\u2019s just fine.\nPrioritizing with the business in mind\nThere are a number of different ways to prioritize features into a product roadmap, and it\u2019s likely your product organization already has its own preferred methodology for this. That said, there are many new machine learning teams working on a large number of projects without a clear prioritization or roadmap. Many companies invest a lot in hiring data scientists and building ML platforms, but then they focus them on solving the wrong problems.\nOne successful approach to this issue is to organize ML product feature ideas by theme and concentrate on a few high ROI projects. To prioritize, start with your company\u2019s mission and near-term strategic objectives. What is the business trying to achieve? Pair a machine learning application directly to one of those objectives, so that when you improve the accuracy metric for your model it directly impacts metrics the business cares about. Build a direct connection between your machine learning application and something the company values.\nFor example, at LinkedIn (where co-author Pete Skomoroch previously worked) the mission was to connect the world\u2019s professionals to make them more productive and successful. A strategic objective for the company was to become the professional profile of record and have complete and up-to-date resume data in the LinkedIn profiles for all professionals. A project idea under this objective was to create a machine learning model to recommend skills a member should add to their profile. A team came up with an impact estimate for the product feature by estimating the expected increase in conversion rate when users were shown ML recommendations.\nPeople You May Know (PYMK) was a successful example of this type of strategic alignment from LinkedIn\u2019s data team. The PYMK recommendation system was trained on data including existing LinkedIn connections, profile similarity, and contacts imported from email to suggest other members a user should connect with. PYMK directly paired what the company wanted to do (drive connections) with a machine learning solution. With a small number of engineers, the data team built a production machine learning model that directly improved the most important metric for the company. Within months it also drove new user growth for the site and created a flywheel of user growth that was critical as LinkedIn became a public company.\nOnce you prune down the set of ideas to ones that align with strategic objectives, there are a number of ways to prioritize them. One effective approach is to get everyone in a room who will be building the system, and have the group form consensus estimates of difficulty, headcount, and impact for each project. Then you can create a chart of impact and ease, rank each project by return on investment and prioritize accordingly. In reality, prioritization is a messy and fluid process, as projects often have dependencies and face staffing limitations or conflicts with other stakeholder deadlines. Scope often needs to be reduced or quality sacrificed to align with other teams or priorities.\nWorking on something that matters to the business is not the only important criteria to consider, since without access to data, your ML system will be useless. In larger companies, it\u2019s best to start by focusing on business units that are eager to work with you and where your help is needed. When you begin development of your first ML product, try to work with teams that already have training data available and help them drive their most important metric. Ideally, that also aligns with the larger set of company priorities.\nResources\nWhere do you go from here as a product manager new to the world of AI? This role is still being defined, but there are already many useful resources out there for you. Here are some great places to start:\n\n\u201cRules of Machine Learning: Best Practices for ML Engineering\u201d (Google)\n\u201cPeople + AI Guidebook\u201d (Google)\n\u201cManaging Machine Learning Projects\u201d (AWS)\n\u201cDesigning Great ML Experiences\u201d (Apple)\nO\u2019Reilly Strata Data & AI Conference\nInsight Fellows Data PM Program\nSpring 2019 Full Stack Deep Learning Bootcamp (Berkeley)\n\u201cRise of the Data Product Manager\u201d (Trey Causey)\n\u201cEverything We Wish We\u2019d Known About Building Data Products\u201d (First Round / DJ Patil)\n\u201cDoes AI make strong tech companies stronger?\u201d (a16z)\n\u201cProduct Management for AI\u201d (Pete Skomoroch)\n\nAI has tremendous potential for those who are willing to learn and to think differently. We hear a lot about AI and corporate transformation; but what we need to make this transformation are people who are willing to lead the changes in corporate culture, help build the data infrastructure, and explore problems that will deliver a measurable return with reasonable investment.\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/pqmrP2XDVmU/"
 },
 {
  "title": "The unreasonable importance of data preparation",
  "content": "In a world focused on buzzword-driven models and algorithms, you\u2019d be forgiven for forgetting about the unreasonable importance of data preparation and quality: your models are only as good as the data you feed them. This is the garbage in, garbage out principle: flawed data going in leads to flawed results, algorithms, and business decisions. If a self-driving car\u2019s decision-making algorithm is trained on data of traffic collected during the day, you wouldn\u2019t put it on the roads at night. To take it a step further, if such an algorithm is trained in an environment with cars driven by humans, how can you expect it to perform well on roads with other self-driving cars? Beyond the autonomous driving example described, the \u201cgarbage in\u201d side of the equation can take many forms\u2014for example, incorrectly entered data, poorly packaged data, and data collected incorrectly, more of which we\u2019ll address below.\nWhen executives ask me how to approach an AI transformation, I show them Monica Rogati\u2019s AI Hierarchy of Needs, which has AI at the top, and everything is built upon the foundation of data (Rogati is a data science and AI advisor, former VP of data at Jawbone, and former LinkedIn data scientist):\nImage courtesy of Monica Rogati, used with permission.\nWhy is high-quality and accessible data foundational? If you\u2019re basing business decisions on dashboards or the results of online experiments, you need to have the right data. On the machine learning side, we are entering what Andrei Karpathy, director of AI at Tesla, dubs the Software 2.0 era, a new paradigm for software where machine learning and AI require less focus on writing code and more on configuring, selecting inputs, and iterating through data to create higher level models that learn from the data we give them. In this new world, data has become a first-class citizen, where computation becomes increasingly probabilistic and programs no longer do the same thing each time they run. The model and the data specification become more important than the code.\nCollecting the right data requires a principled approach that is a function of your business question. Data collected for one purpose can have limited use for other questions. The assumed value of data is a myth leading to inflated valuations of start-ups capturing said data. John Myles White, data scientist and engineering manager at Facebook, wrote: \u201cThe biggest risk I see with data science projects is that analyzing data per se is generally a bad thing. Generating data with a pre-specified analysis plan and running that analysis is good. Re-analyzing existing data is often very bad.\u201d John is drawing attention to thinking carefully about what you hope to get out of the data, what question you hope to answer, what biases may exist, and what you need to correct before jumping in with an analysis[1]. With the right mindset, you can get a lot out of analyzing existing data\u2014for example, descriptive data is often quite useful for early-stage companies[2].\nNot too long ago, \u201csave everything\u201d was a common maxim in tech; you never knew if you might need the data. However, attempting to repurpose pre-existing data can muddy the water by shifting the semantics from why the data was collected to the question you hope to answer. In particular, determining causation from correlation can be difficult. For example, a pre-existing correlation pulled from an organization\u2019s database should be tested in a new experiment and not assumed to imply causation[3], instead of this commonly encountered pattern in tech:\n\nA large fraction of users that do X do Z\nZ is good\nLet\u2019s get everybody to do X\n\nCorrelation in existing data is evidence for causation that then needs to be verified by collecting more data.\nThe same challenge plagues scientific research. Take the case of Brian Wansink, former head of the Food and Brand Lab at Cornell University, who stepped down after a Cornell faculty review reported he \u201ccommitted academic misconduct in his research and scholarship, including misreporting of research data, problematic statistical techniques [and] failure to properly document and preserve research results.\u201d One of his more egregious errors was to continually test already collected data for new hypotheses until one stuck, after his initial hypothesis failed[4]. NPR put it well: \u201cthe gold standard of scientific studies is to make a single hypothesis, gather data to test it, and analyze the results to see if it holds up. By Wansink\u2019s own admission in the blog post, that\u2019s not what happened in his lab.\u201d He continually tried to fit new hypotheses unrelated to why he collected the data until he got a null hypothesis with an acceptable p-value\u2014a perversion of the scientific method.\nData professionals spend an inordinate amount on time cleaning, repairing, and preparing data\nBefore you even think about sophisticated modeling, state-of-the-art machine learning, and AI, you need to make sure your data is ready for analysis\u2014this is the realm of data preparation. You may picture data scientists building machine learning models all day, but the common trope that they spend 80% of their time on data preparation is closer to the truth.\n\nThis is old news in many ways, but it\u2019s old news that still plagues us: a recent O\u2019Reilly survey found that lack of data or data quality issues was one of the main bottlenecks for further AI adoption for companies at the AI evaluation stage and was the main bottleneck for companies with mature AI practices.\nGood quality datasets are all alike, but every low-quality dataset is low-quality in its own way[5]. Data can be low-quality if:\n\nIt doesn\u2019t fit your question or its collection wasn\u2019t carefully considered;\nIt\u2019s erroneous (it may say \u201ccicago\u201d for a location), inconsistent (it may say \u201ccicago\u201d in one place and \u201cChicago\u201d in another), or missing;\nIt\u2019s good data but packaged in an atrocious way\u2014e.g., it\u2019s stored across a range of siloed databases in an organization;\nIt requires human labeling to be useful (such as manually labeling emails as \u201cspam\u201d or \u201cnot\u201d for a spam detection algorithm).\n\nThis definition of low-quality data defines quality as a function of how much work is required to get the data into an analysis-ready form. Look at the responses to my tweet for data quality nightmares that modern data professionals grapple with.\nThe importance of automating data preparation\nMost of the conversation around AI automation involves automating machine learning models, a field known as AutoML. This is important: consider how many modern models need to operate at scale and in real time (such as Google\u2019s search engine and the relevant tweets that Twitter surfaces in your feed). We also need to be talking about automation of all steps in the data science workflow/pipeline, including those at the start. Why is it important to automate data preparation?\n\nIt occupies an inordinate amount of time for data professionals. Data drudgery automation in the era of data smog will free data scientists up for doing more interesting, creative work (such as modeling or interfacing with business questions and insights). \u201c76% of data scientists view data preparation as the least enjoyable part of their work,\u201d according to a CrowdFlower survey.\nA series of subjective data preparation micro-decisions can bias your analysis. For example, one analyst may throw out data with missing values, another may infer the missing values. For more on how micro-decisions in analysis can impact results, I recommend Many Analysts, One Data Set: Making Transparent How Variations in Analytic Choices Affect Results[6] (note that the analytical micro-decisions in this study are not only data preparation decisions). Automating data preparation won\u2019t necessarily remove such bias, but it will make it systematic, discoverable, auditable, unit-testable, and correctable. Model results will then be less reliant on individuals making hundreds of micro-decisions. An added benefit is that the work will be reproducible and robust, in the sense that somebody else (say, in another department) can reproduce the analysis and get the same results[7];\nFor the increasing number of real-time algorithms in production, humans need to be taken out of the loop at runtime as much as possible (and perhaps be kept in the loop more as algorithmic managers): when you use Siri to make a reservation on OpenTable by asking for a table for four at a nearby Italian restaurant tonight, there\u2019s a speech-to-text model, a geographic search model, and a restaurant-matching model, all working together in real time. No data analysts/scientists work on this data pipeline as everything must happen in real time, requiring an automated data preparation and data quality workflow (e.g., to resolve if I say \u201ceye-talian\u201d instead of \u201cit-atian\u201d).\n\nThe third point above speaks more generally to the need for automation around all parts of the data science workflow. This need will grow as smart devices, IoT, voice assistants, drones, and augmented and virtual reality become more prevalent.\nAutomation represents a specific case of democratization, making data skills easily accessible for the broader population. Democratization involves both education (which I focus on in my work at DataCamp) and developing tools that many people can use.\nUnderstanding the importance of general automation and democratization of all parts of the DS/ML/AI workflow, it\u2019s important to recognize that we\u2019ve done pretty well at democratizing data collection and gathering, modeling[8], and data reporting[9], but what remains stubbornly difficult is the whole process of preparing the data.\nModern tools for automating data cleaning and data preparation\nWe\u2019re seeing the emergence of modern tools for automated data cleaning and preparation, such as HoloClean and Snorkel coming from Christopher R\u00e9\u2019s group at Stanford. HoloClean decouples the task of data cleaning into error detection (such as recognizing that the location \u201ccicago\u201d is erroneous) and repairing erroneous data (such as changing \u201ccicago\u201d to \u201cChicago\u201d), and formalizes the fact that \u201cdata cleaning is a statistical learning and inference problem.\u201d All data analysis and data science work is a combination of data, assumptions, and prior knowledge. So when you\u2019re missing data or have \u201clow-quality data,\u201d you use assumptions, statistics, and inference to repair your data. HoloClean performs this automatically in a principled, statistical manner. All the user needs to do is \u201cto specify high-level assertions that capture their domain expertise with respect to invariants that the input data needs to satisfy. No other supervision is required!\u201d\nThe HoloClean team also has a system for automating the \u201cbuilding and managing [of] training datasets without manual labeling\u201d called Snorkel. Having correctly labeled data is a key part of preparing data to build machine learning models[10]. As more and more data is generated, manually labeling it is unfeasible. Snorkel provides a way to automate labeling, using a modern paradigm called data programming, in which users are able to \u201cinject domain information [or heuristics] into machine learning models in higher level, higher bandwidth ways than manually labeling thousands or millions of individual data points.\u201d Researchers at Google AI have adapted Snorkel to label data at industrial/web scale and demonstrated its utility in three scenarios: topic classification, product classification, and real-time event classification.\nSnorkel doesn\u2019t stop at data labeling. It also allows you to automate two other key aspects of data preparation:\n\nData augmentation\u2014that is, creating more labeled data. Consider an image recognition problem in which you are trying to detect cars in photos for your self-driving car algorithm. Classically, you\u2019ll need at least several thousand labeled photos for your training dataset. If you don\u2019t have enough training data and it\u2019s too expensive to manually collect and label more data, you can create more by rotating and reflecting your images.\nDiscovery of critical data subsets\u2014for example, figuring out which subsets of your data really help to distinguish spam from non-spam.\n\nThese are two of many current examples of the augmented data preparation revolution, which includes products from IBM and DataRobot.\nThe future of data tooling and data preparation as a cultural challenge\nSo what does the future hold? In a world with an increasing number of models and algorithms in production, learning from large amounts of real-time streaming data, we need both education and tooling/products for domain experts to build, interact with, and audit the relevant data pipelines.\nWe\u2019ve seen a lot of headway made in democratizing and automating data collection and building models. Just look at the emergence of drag-and-drop tools for machine learning workflows coming out of Google and Microsoft. As we saw from the recent O\u2019Reilly survey, data preparation and cleaning still take up a lot of time that data professionals don\u2019t enjoy. For this reason, it\u2019s exciting that we\u2019re now starting to see headway in automated tooling for data cleaning and preparation. It will be interesting to see how this space grows and how the tools are adopted.\nA bright future would see data preparation and data quality as first-class citizens in the data workflow, alongside machine learning, deep learning, and AI. Dealing with incorrect or missing data is unglamorous but necessary work. It\u2019s easy to justify working with data that\u2019s obviously wrong; the only real surprise is the amount of time it takes. Understanding how to manage more subtle problems with data, such as data that reflects and perpetuates historical biases (for example, real estate redlining) is a more difficult organizational challenge. This will require honest, open conversations in any organization around what data workflows actually look like.\nThe fact that business leaders are focused on predictive models and deep learning while data workers spend most of their time on data preparation is a cultural challenge, not a technical one. If this part of the data flow pipeline is going to be solved in the future, everybody needs to acknowledge and understand the challenge.\nMany thanks to Angela Bassa, Angela Bowne, Vicki Boykis, Joyce Chung, Mike Loukides, Mikhail Popov, and Emily Robinson for their valuable and critical feedback on drafts of this essay along the way.\n\n\n\n[1] For example, let\u2019s say that you have existing data on how many users on your e-commerce website have clicked on items after a search. If you want to repurpose this data later on to rank your website\u2019s search results, you need to correct for the bias introduced by the initial order when the data was collected.\n\n[2] For example, Mikhail Popov, a data analyst at the Wikimedia Foundation, told me that they\u2019re still getting new descriptive analyses out of years of existing data to get new insights on their users (especially editors) and trends. As a specific example: one of their biggest data sources is editing history across all their projects, publicly available at Analytics Datasets, which they use to answer ad-hoc questions like \u201cacross the 300 languages of Wikipedia, what % of newly registered accounts make an edit in their first 24 hours?\u201d or to look at how readership traffic (pageviews also available publicly) has correlated historically with editing activity \u2013 which are all descriptive insights into their many communities.\n\n[3] Related is the supreme focus on \u201cbig data.\u201d \u201cSmall data\u201d, when collected in a principled, thoughtful manner can have a lot of signal. Look no further than the fact that a poll of only 1,004 Americans represents 260 million people with only a 3 percent margin of error, when the sample is representative (this is rarely the case but there are sophisticated correction methods that can get experts close). Similarly, \u201cthick (or qualitative) data\u201d can often tell us more than merely collecting more and more \u201cbig data\u201d.\n\n[4] This is an example of what\u2019s known as p-hacking.\n\n[5] To paraphrase Hadley Wickham\u2019s rendition of Tolstoy in this paper.\n\n[6] In which 29 expert teams are given \u201cthe same data set to address the same research question: whether soccer referees are more likely to give red cards to dark-skin-toned players than to light-skin-toned players.\u201d 69% said \u201cyes\u201d while 31% said \u201cno\u201d. What\u2019s even more concerning is that most teams were even more confident of their own results after seeing the other teams\u2019 analyses. According to the paper, \u201cThese findings suggest that significant variation in the results of analyses of complex data may be difficult to avoid, even by experts with honest intentions.\u201d\n\n[7] Yet another benefit is that building such automated data preparation pipelines is essentially a form of preregistering analytical techniques (specifying your methodology before actually doing it so you can\u2019t alter it as a function of what you find in your data), which also reduces human bias. More and more research scientists are advocating for preregistration, particularly with the ongoing reproducibility crisis in scientific research, along with its credibility crisis.\n\n[8] With automated machine learning packages such as TPOT and drag-and-drop interfaces like Azure\u2019s automated machine learning tool.\n\n[9] Such as R Markdown and Jupyter Notebooks.\n\n[10] For example, if you\u2019re building a spam detection model, then you need to feed the model both spam and non-spam emails, labelled correctly as \u201cspam\u201d or \u201cnon-spam\u201d (called training data as you use it to train your model). To see how important the challenge of getting good quality labelled data, look no further than data labelling start-up Scale AI\u2019s recent $100 million Series C funding round, which brought their valuation past $1 billion (also note that Scale AI is still using humans to label their data on the back end).\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/Pt-JBUG44GM/"
 },
 {
  "title": "Four short links: 24 March 2020",
  "content": "\nPotential Distributed Reading Group on Distributed Systems \u2014 for some folks, this will be a great time to start reading groups to work through papers. You\u2019ll never get a time with less physical distraction. (Just remember to ration your socials time or you and your time will vanish into the maelstrom.)\nJitsi Meet \u2014 open source videoconferencing.\nPigweed \u2014 open source collection of [\u2026] modules built to enable faster and more reliable development on 32-bit microcontrollers. See also Google Open Source blog)\nFASTBuild \u2014 a high-performance, open source build system for Windows, Linux, and OS X. It supports highly scalable compilation, caching, and network distribution. From the largest studios in the world to the smallest independent developers, FASTBuild is used in production every day to develop for PC/Mac/Linux, Consoles, Smartphones, and retro systems.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/1Vby7nmqKsw/"
 },
 {
  "title": "3 ways to confront modern business challenges",
  "content": "I interviewed four business leaders in late 2019 to get their perspectives on the biggest obstacles and opportunities organizations are facing.\nCraig Lemasters was the president and CEO of Assurant Solutions. Under his leadership, Assurant Solutions doubled in size to $4B, underwent a digital transformation to expand an offering of risk management solutions in the connected living space, and became established in 25 new markets around the world. After Lemasters left Assurant, he bought a company called GXG where, as the chief executive officer, he focuses on accelerating the growth of companies through rapid-cycle learning. (Disclosure: GXG is a partner of Science House, a consultancy I co-direct.)\nJen Bruno is the SVP of culture and human capital at LPL Financial, a firm founded to help entrepreneurial financial advisors offer independent financial guidance. Early in her career, Bruno was a florist who dreamed of working at the Walt Disney company. The dream became reality. (Disclosure: LPL is a client of my consultancy.)\nDana Codispoti is the head of HR transformation at AIG. Previously, she worked at BNY Mellon and Morgan Stanley, and in multiple industries spanning consumer products, pharmaceuticals, and hospitality. With an engineering background and a mind for data and analytics, Codispoti is adept at leading change in processes that have scaled across large companies, with an eye for both humanity and technology.\nJames Jorasch is the founding CEO of Science House, a New York-based consultancy that I co-direct. For 14 years prior to founding Science House, Jorasch was the head of inventing at Walker Digital. He\u2019s a named inventor on more than 750 patents, including the patents at the core of Priceline, and his innovation work spans many industries, including retail, health care, and gaming.\u00a0\nBelow, you\u2019ll find notable themes that emerged during the discussions. You can see the full interviews here.\nContinuous learning and continuous improvement\nWhen people ask Craig Lemasters how long he ran Assurant Solutions, he says 44 quarters rather than 11 years.\n\u201cThat\u2019s how we think,\u201d he said. \u201cHow do you free up time to think beyond a quarter or two or a year or two? We can do that. We can get to that place.\u201d\nBut when Assurant\u2019s distribution model\u2014big box retailers\u2014started collapsing, Lemasters wondered how he would shape the company\u2019s future while focusing on the short term.\nHe knew it started with him as a CEO, but he didn\u2019t know that other \u201clonely CEOs\u201d were stuck in the same place. He engaged GXG (a company he later purchased) to help him over the hurdle by exposing him to the wisdom of others who navigated the same path. Continuous learning, especially from others who have developed wisdom from being in the same position, helps leaders get unstuck and become more agile.\nContinuous learning is also required to understand the relationship between humanity and technology.\n\u201cTechnology is driving and enabling at the same time,\u201d Dana Codispoti said. \u201cIt\u2019s a matter of how we use it. We need the human mind.\u201d\nFrom an HR perspective, Codispoti said, we need to go faster to get our minds ready. Companies should understand, among other things, the power of robotics and AI, along with the art of the possible, \u201cwhile they are fixing the foundation,\u201d Codispoti said. Too often, companies try to grasp at the next big thing without laying the foundation for learning first.\n\u201cThere\u2019s a whole world of things to learn,\u201d Codispoti said. \u201cI look at it as an enabler.\u201d\nJen Bruno agreed. \u201cEvery business professional should consider themselves a continuous learner,\u201d Bruno said. She noted that people need to be \u201cchange ready,\u201dand get better at applying what they know in different areas for the greater good. Every company should get employees excited and engaged to learn because change keeps happening \u201cfaster than we can imagine.\u201d\nWhat makes a company a world-class learning organization?\n\u201cWhen people truly are in a mindset of continuous improvement,\u201d Bruno said. \u201cWe can learn something from every person we meet. That\u2019s good for business. Share talent and knowledge, and foster collaboration for greater outcomes.\u201d\nBusiness lessons from technology processes\nCompanies need a clear vision in a complex world, Codispoti said. \u201cCreate a north star that people can align to, that gets people excited about solving a problem,\u201d she said. \u201cWithout it, they spin and spin and spin. If people don\u2019t know how their work is value-add, you lose engagement. It ties to the enterprise vision.\u201d\nAs more companies shift to Agile software development and, more importantly, an Agile mindset, the culture of companies has begun to mimic the iterative nature of technology. Smaller, granular pieces need to communicate with each other in the most effective way. This is true for microservices architecture, for example, and for people across teams.\nCodispoti said that creating a process requires an end-to-end vision, but silos often lead to fragments being created piecemeal. \u201cOnce [a broken process] is enabled through technology and you want to make changes, it\u2019s hard and people blame the technology,\u201d Codispoti said.\nHuge problems, James Jorasch said, need to be \u201cdistilled down to something that a client can understand and take action on.\u201d Science House works with large enterprise clients, often on transformational software projects that can span years. The parallel between technology and people applies here, too.\u00a0 Making complex projects and transformations more modular creates a parallel impact on people and organizational structures, changing the nature of their responsibilities and spans of control. Bringing modular pieces together, whether the modules are temporal or functional, changes the role of traditional hierarchical organizational structures as they adapt to increased complexity.\n\u201cThe nature of management is changing, and not just because of Agile,\u201d Jorasch said. \u201cIt\u2019s a different way of thinking. Managers have gone from managing people to managing processes, mindsets, skills, and problems.\u201d\nThey also need to manage information flow into and from these groups.\n\u201cThere are lessons learned from tech that will be applicable to people,\u201d Jorasch said. \u201cWhere are the bottlenecks? What are the styles of thinking you need? Focus on what\u2019s essential. How do you get the right information to the right person at the right time?\u201d\nHumility is an asset\nOne of the themes that came throughout the interviews was the need for humility. Without it, companies tend to stay inward looking and siloed.\n\u201cCompanies struggle with cross-collaboration,\u201d Codispoti said. \u201cPeople tend to work in silos. They need to partner with experts in other areas. They don\u2019t need to do it on their own, and they\u2019re missing opportunities.\u201d\nBruno and Lemasters both cited humility as a critical trait for leaders. Humility gives people the energy to cross over into an unfamiliar area, Bruno said, and creates the capacity for empathy.\n\u201cI look for the humility quotient,\u201d Lemasters said. \u201cA willingness for leaders to embrace outside thinking and ideas. Some would call it criticism, but it isn\u2019t. Have the humility to accept people who have wisdom in their swim lanes. We learn quickly. There\u2019s goodness in humanity, and people want to help.\u201d\nJorasch often cites the need for not taking ourselves too seriously during innovation sessions, for example, because one person\u2019s silly or half-formed comment gives another person a great idea. Humility helps prevent people from having to project authority or expertise every time they speak. With humility comes better listening; more honest, authentic input; less defensiveness; and more collaboration based on respect for one\u2019s peers\u2019 opinions.\nBe sure to check out the full interviews for additional insights.\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/_YW6drzYyR4/"
 },
 {
  "title": "An enterprise vision is your company\u2019s North Star",
  "content": "Rita J. King, co-director and EVP for business development at Science House, recently conducted a series of interviews with business leaders, exploring the challenges and hurdles companies face in evolving business landscapes. In this interview, King chats with Dana Codispoti, head of HR Transformation at AIG, about how to address the human factor in business transformations to keep employees engaged and connected to the overall business mission. They also discuss the future of the human-technology relationship and why technology should be viewed as an enabler rather than a replacement for human contributions.\nHere are some highlights from their conversation:\nWith technology iterating and improving at ever-increasing speeds, companies are challenged with how best to utilize data and analytics to inform new technology decisions. Codispoti stresses that it\u2019s imperative to start with the foundation, the \u201cbuilding blocks,\u201d and not jump straight to the innovation or \u201cshiny object.\u201d The key, Codispoti notes, to successfully navigating new technologies and processes lies with the people and their engagement with the company\u2019s overall vision. \u201cOne of the most important things you need to do in technology initiatives,\u201d she says, \u201cis to create a vision to help people understand what they are driving toward. I see a lot of work being done in the trenches where people don\u2019t see the bigger picture\u2014everybody\u2019s working on an individual project or set of projects, but they can\u2019t understand how it fits into a broader picture. If there isn\u2019t a vision for the company, create one, or create a North Star that people can align to. That gets people excited about a problem; it gets people excited about participating in the solution. \u2026 If people don\u2019t know why their work is value add and how it ties to a broader picture, you lose engagement.\u201d (01:58)\nMitigating risk is a hurdle for any company facing changing technology and business processes. Codispoti says the solution lies in breaking out of silos and comfort zones to leverage the expertise of colleagues across an organization. \u201cI find companies struggle with cross collaboration,\u201d She explains. \u201cIf someone\u2019s, for example, working in a business, they need to leverage their partners. In my case, it would be HR, finance, the risk organization, the audit, and legal folks. I think people tend to work in silos, and they need to lift up their heads, look around and say, these people are experts in those areas. Talk through and partner with them to understand the problems they\u2019re solving for so that they can help point out the risk. People think they need to do all that on their own, and they\u2019re missing opportunities to mitigate risk. \u2026 It\u2019s about breaking through silos and pointing out how collaboration is additive\u2014when you work in teams, you get more. People also have a mindset that \u2018I need to fix this for my area,\u2019 and it\u2019s not an enterprise mentality. As you go through these transformations, it\u2019s about trying to influence the culture to say you wear two hats: one is for whatever you\u2019re working on and one is for the enterprise, and lead with that enterprise mindset.\u201d (05:28)\nLooking toward the future and humanity\u2019s evolving relationship with technology, Codispoti stresses that machines will always need people and humans should not fear being replaced. \u201cThere\u2019s a large level of awareness around technology driving the future in a lot of ways, but I think there\u2019s also fear that technology is going to take over humanity\u2014we know that\u2019s not the case,\u201d She says. \u201cYou need both. \u2026 At the end of the day, the work is in the work, in the process, in the culture, in the people, and then technology becomes an enabler. So, it\u2019s driving and enabling at the same time, but I think everybody needs to co-exist. Nobody\u2019s going to be wiped out by technology; it\u2019s a matter of how we use it and we recognize that it can do things faster than we can, but in some ways we need the human mind to enhance whatever technology is doing.\u201d(14:40)\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/UNR8GT2bHms/"
 },
 {
  "title": "Leaders need to mobilize change-ready workforces",
  "content": "Rita J. King, co-director and EVP for business development at Science House, recently conducted a series of interviews with business leaders, exploring the challenges and hurdles companies face in evolving business landscapes. In this interview, King chats with Jen Bruno, SVP of culture and human capital at LPL Financial, about mobilizing a change-ready workforce, leadership rotation programs, and fostering continuous learning.\nHere are some highlights from their conversation:\nThe reality, Bruno argues, is that businesses are in a state of change. And while humans tend to have a hard time with change, the time is ripe for people to take advantage of the coming changes to grow and develop. \u201cCompanies have a hard time mobilizing a workforce that is change-ready because people inherently want to do what they know; we build our careers on the skills that have allowed us to move to the next level. We\u2019re at a time right now where people can look beyond that and use those skills in another department or a new area; crossing over can enable the imagination, the creativity, and the innovation that companies so desperately want in order to grow and best serve their customers. It\u2019s an exciting opportunity for people to think of themselves as change agents and be willing to crossover and work in different areas, leveraging what they know and learning what they don\u2019t know. (06:23)\nBridging culture gaps\u2014and communication gaps\u2014 between departments is essential, Bruno says, to enable teams to work together efficiently and effectively to reap better outcomes. Creating these working relationship bridges, she argues, starts at the top. \u201cI\u2019m a big fan of having leaders rotate through the different jobs within an organization. The true way to learn empathy is to do the work yourself and understand what the people in specific roles go through on a day-to-day business. You\u2019ll have a better understanding of the business operation as a whole. I think it makes you a better business leader because it does help develop that empathy, and it allows you to build your network of people internally, and that\u2019s really important too.\u201d (10:56)\nThe key to weathering the transition to what work will become in the future, Bruno argues, is continuous learning. \u201cEvery business professional should consider themselves a continuous learner. There is so much to learn from other organizations that have similar situations, from business people we have things in common with, and it\u2019s important to be change-ready and willing to leverage what you know in different areas for the greater good. We should all be preparing ourselves as much as we can so we can bring value to the companies we work for, whatever that might look like.\u201d To that end, it\u2019s important for learning and development approaches to evolve, she says, to be more effective in the face of the changes coming our way. \u201cI hope I never see a PowerPoint presentation being held up in a room for an hour while somebody talks to an audience, because that\u2019s not really fostering learning in a way that gets people excited and engaged.\u201d (13:59)\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/JICZx5XMzRM/"
 },
 {
  "title": "Great leaders inspire innovation and creativity from within their workforces",
  "content": "Rita J. King, co-director and EVP for business development at Science House, recently conducted a series of interviews with business leaders, exploring the challenges and hurdles companies face in evolving business landscapes. In this interview, King chats with James Jorasch, founding CEO of Science House, about the importance of innovation and how to inspire and harness the creative talent in your workforce.\nHere are some highlights from their conversation:\nIt\u2019s important, Jorasch says, to appropriate the techniques of innovation that bring together ideas from disparate sources and apply those to people in your company. \u201cWe need people also to collide; people with different perspectives, different concepts, different ideas need to come together over and over again.\u201d He also notes that invention isn\u2019t only an innate talent; it can also be a learned skill. \u201cWe train many people, and I would say that everyone can invent. Believe in yourself, relax, find a problem, come up with a solution, keep going. It\u2019s not a complicated thing. Just believe in yourself and try. Trying is probably 90% of it.\u201d (05:15)\nTo effectively get the creative juices flowing, Jorasch recommends ditching large meetings, as they allow people to avoid contributing by simply hiding in the crowd. \u201cWhen you bring a meeting down to just two people, there\u2019s no hiding, there\u2019s no, \u2018Well, I\u2019m going to be on my cell phone. We\u2019re working on this.\u2019 There\u2019s no getting away from what you\u2019re there to do. It is that sense of focus that you get from two people that really ignites the imagination process.\u201d That focus, he says, is key to addressing the new challenges coming. \u201cThere\u2019s a lot that can be accomplished from creative pairs. It is a purpose driven, very focused way of tackling problems, and tackling very complicated and very deep problems. It takes away everything else\u2014you\u2019re lasered in on that one thing for, potentially, hours at a time. And that\u2019s what it takes, right? 10-second solutions are not going to cut it in this world.\u201d (07:29)\nThe data Science House has gathered from large companies over the years has afforded interesting insights into the changing nature of management, Jorasch says. For instance, in our increasingly Agile approaches to business and systems, the well-established, traditional hierarchy of individual contributor, manager, director, VP, SVP, and so forth, is no longer a great fit. \u201cWe have rules around the standard hierarchy,\u201d he observes. \u201cWe don\u2019t really have rules, per se, around Agile. And we\u2019re seeing a collision of managers and directors now saying, \u2018I\u2019ve been a director for 15 years\u2014what\u2019s my role now with these Agile teams?\u2019 People are starting to question what it is they\u2019re supposed to do.\u201d And it\u2019s not only evolving cultures and approaches challenging leaders, but evolving technologies, too. \u201cThe idea of using microservices, for example, is a very different way of thinking,\u201d he notes. \u201cThose managers and directors and VPs are evolving from managing people to managing a process or managing mindsets and skills of the workers, and managing problems or managing the information flow into these groups. That\u2019s going to require a very different set of skills and new types of training.\u201d (13:10)\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/Uz6cibmqT1I/"
 },
 {
  "title": "Strong leaders forge an intersection of knowledge and experience",
  "content": "Rita J. King, co-director and EVP for business development at Science House, recently conducted a series of interviews with business leaders, exploring the challenges and hurdles companies face in evolving business landscapes. In this interview, King chats with Craig Lemasters, CEO of Global Executive Group, about what companies face when navigating the digital transformation. They also talk about the power of humility and what it means to be an agile leader.\n\n\n\nHere are some highlights from their conversation:\n\n\n\n\u201cDigital transformation\u201d means something different to every company. The key to successfully traversing the transformation, Lemasters explains, is to identify specifically what it means to a particular company. In his case, he was running a global insurance company called Assurance Solutions, and he identified two specific areas of focus: \u201cwe knew we needed to have a digital relationship with the end consumer. \u2026 [And] we knew we needed to have some type of digital distribution model.\u201d (02:33)\n\n\n\nTo succeed in a new space, Lemasters came to realize, requires both knowledge and experience\u2014an intersection Lemasters uses to define \u201cwisdom.\u201d This realization led to Lemasters\u2019 big \u201cah-ha!\u201d moment: \u201cThe stumbling block for digital was, quite frankly, that we didn\u2019t have either knowledge or experience on digital, and it started with me. I mean, it started with me even as a CEO. I started looking at my team and realized none of us really had a lot of knowledge and experience on this thing called digital. The whole \u201cah-ha\u201d experience was that speed bump. What if we inserted knowledge and experience into the room\u2014could we get to the point much quicker? That\u2019s what\u2019s become my passion \u2014 how do we interject this thing called wisdom into the conversation, into the process, just to get us there faster?\u201d (05:40)\n\n\n\nLemasters argues that humility is key to being a strong, agile leader. Being able to make decisions at the rate of speed required today takes, if not a village, at least some additional expertise. \u201cThe \u2018humility quotient\u2019 is the willingness for leaders to literally embrace outside thinking,\u201d Lemasters explained. \u201cSome would call it criticism; it really isn\u2019t. I mean, most of this work is about the unknown, and you just haven\u2019t been there yet. What I found is if we just have enough humility to accept that and actually invite in some people who have the wisdom in these swim lanes, increasing the speed at which we learn, we get over ourselves pretty quickly.\u201d (11:16)\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/cQpks9Bw11E/"
 },
 {
  "title": "Four short links: 23 March 2020",
  "content": "\nStanza: A Python Natural Language Processing Toolkit for Many Human Languages \u2014 Stanza features a language-agnostic fully neural pipeline for text analysis, including tokenization, multi-word token expansion, lemmatization, part-of-speech and morphological feature tagging, dependency parsing, and named entity recognition. Code and models available for 66 languages.\nDropbear SSH \u2014 Dropbear is a relatively small SSH server and client. It runs on a variety of POSIX-based platforms. Dropbear is open source software, distributed under an MIT-style license. Dropbear is particularly useful for \u201cembedded\u201d-type Linux (or other Unix) systems, such as wireless routers.\nPrivate Kit \u2014 an open source privacy preserving system for logging locations and sharing with researchers on your own terms\u2014e.g., to track contact in coronavirus without losing control.\nWhy the EAX Register is Called That \u2014 some neat history, showing how deep the roots of backward compatibility are.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/vMm8_OsqJ-4/"
 },
 {
  "title": "Four short links: 20 March 2020",
  "content": "\nNASCAR Replaces Canceled Races with Esports Featuring Pro Drivers (Engadget) \u2014 the world is getting weirder.\nFirebase Scrutinized By Antitrust Regulators \u2014 Firebase tools give Google, the internet\u2019s top ad seller, information on what consumers are doing inside apps that it can exploit to target ads to users, according to makers of Firebase alternatives.\nJourney into Observability: Glitch\u2019s Story (Mads Hartmann) \u2014 an easy-to-follow and honest recap of their journey from lots of logging to being able to look at heatmaps and resolve more problems.\nHyphal Mesh \u2014 30 mins. 2 convos, 1-on-1. Nifty idea for connecting people in these weird times.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/GGLbZECmPJI/"
 },
 {
  "title": "6 trends framing the state of AI and ML",
  "content": "O\u2019Reilly online learning is a trove of information about the trends, topics, and issues tech leaders need to know about to do their jobs. We use it as a data source for our annual platform analysis, and we\u2019re using it as the basis for this report, where we take a close look at the most-used and most-searched topics in machine learning (ML) and artificial intelligence (AI) on O\u2019Reilly[1].\nOur analysis of ML- and AI-related data from the O\u2019Reilly online learning platform indicates:\n\nUnsupervised learning surged in 2019, with usage up by 172%.\nDeep learning cooled slightly in 2019, slipping 10% relative to 2018, but deep learning still accounted for 22% of all AI/ML usage.\nAlthough TensorFlow grew by just 3%, it, too, garnered 22% share of AI/ML usage in 2019.\nPyTorch looks like a contender: it posted triple-digit growth in usage share rates in both 2018 and 2019.\nReinforcement learning fell by 5% in 2019; it\u2019s up hugely\u20141,500+%\u2014since 2017, however.\nSustained strength in unsupervised learning, neural networks, reinforcement learning, etc., demonstrates that organizations are experimenting with advanced ML tools and methods.\n\nFigure 1. AI/ML topics on the O\u2019Reilly online learning platform with the most usage in 2019 (left) and the rate of change for each topic (right).\nGrowth in ML and AI is unabated\nEngagement with the artificial intelligence topic continues to grow, up 88% in 2018 and 58% in 2019 (see Figure 1), outpacing share growth in the much larger machine learning topic (+14% in 2018, up 5% in 2019). Aggregating artificial intelligence and machine learning topics accounts for nearly 5% of all usage activity on the platform, a touch less than, and growing 50% faster than, the well-established \u201cdata science\u201d topic (see Figure 2).\nData engineering remains the largest topic in the data category with just over 8% usage share on the platform (Figure 2). But the data engineering share is down about 8% in 2019, mostly from declines in engagement with data management topics.\nFigure 2. High-level data topics on the O\u2019Reilly online learning platform with the most usage (left) and and the rate of change for each topic (right).\nUnsupervised learning is growing\nInterest in the unsupervised learning topic increased significantly, with usage up by 53% in 2018 and by 172% in 2019[2] (see Figure 1). What\u2019s driving this growth?\nFirst, for most people and most use cases, supervised learning serves as the default, assumed strategy for machine learning. That makes unsupervised learning worth noting as a separate topic, given the growth in engagement driven by more sophisticated users, improved tools, and use cases not easily addressed with supervised methods. By analogy, users are more apt to engage with specific supervised learning methods\u2014e.g., linear and logistic regressions, support vector machines\u2014than with the canonical topic of supervised learning itself.\nUnsupervised learning, by contrast, isn\u2019t as well understood, even if the names of its methods\u2014e.g., clustering and association\u2014and its applications (neural networks) are familiar to many users.\nIn all likelihood, the surge in unsupervised learning activity on O\u2019Reilly is being driven by a lack of familiarity with the term itself, as well as with its uses, benefits, requirements, etc. It\u2019s likely, too, that the visible success of unsupervised learning in neural networks and deep learning[3] has helped spur interest, as has the diversity of open source tools, libraries, tutorials, etc., that support unsupervised learning. That some of these tools (scikit-learn, PyTorch, and TensorFlow) are also Python-based doesn\u2019t hurt, either.\nUsage in advanced techniques is up\u2014mostly\nIt\u2019s said that the success of neural networks and, especially, deep learning\u2014neither of which is new\u2014helped spur the resurrection of a number of other disused or neglected ideas.\nOne example is reinforcement learning, which experienced an exponential spike in usage on the O\u2019Reilly platform in 2018\u2014growing by 1,612%\u2014before regressing slightly (-5%) in 2019 (see Figure 1).\nLooking at AI/ML topic detail, we see usage in neural networks continuing its upward trend\u2014up 52% in 2018; up 17% in 2019\u2014but the related topic of deep learning dropped 10% in 2019. The drop in deep learning seems likely a function of inter-year noise and not evidence of an emerging trend, given the significant usage growth in 2018 (+52%). These closely related topics are popular: aggregating neural networks, deep learning, and TensorFlow usage nets nearly half (47%) of all AI/ML category usage, showing a slight decline (-3%) in 2019 after growing 24% in 2018.\nIn our \u201cAI adoption in the enterprise 2020\u201d survey, we found that deep learning was the most popular ML method among companies that are evaluating AI. Among companies using AI to support production use cases, deep learning was No. 2[4]. It might be that\u2014at 1% of platform usage and 22% of all AI/ML usage\u2014deep learning has approached its asymptote. Growth could be slow from here on out.\nThe rising AI/ML tide lifts (almost) all boats\nAnother topic showing consistent growth is natural language processing (NLP) (see Figure 1). Its growth rate isn\u2019t spectacular\u2014+15% in 2018, +9% in 2019\u2014but NLP now accounts for about 12% of all AI/ML usage on O\u2019Reilly. That\u2019s about 6x the share of unsupervised learning and 5x the share of reinforcement learning usage.\nInterest in some methods or applications of ML seems to be waning, however. For example, the chatbots topic continues to decline, first by 17% in 2018 and by 34% in 2019. This is probably a reflection of the comparative maturity of the space. The chatbot was one of the first applications of AI in experimental and production usage. This likely doesn\u2019t portend the end of interactions with occasionally helpful\u2014and still sometimes horrifying\u2014customer service chatbots.\nComputer vision usage shows a slow decline, falling by 3% in 2018 and 2% in 2019. Probably more noise than trend, moreover, computer vision accounts for about twice as much usage activity as the fast growing unsupervised learning topic.\nPython-based tools are ascendant in AI/ML\nReports of Torch\u2019s death are somewhat misleading. In fact, PyTorch\u2014a wrapper that permits users to call Torch\u2019s ML libraries from Python\u2014posted triple-digit growth in usage in just the last few years, surging by almost 400% in 2018 and by 111% in 2019 (see Figure 1). PyTorch\u2019s popularity is probably a function of the success of Python itself, particularly for ML and AI: vanilla Torch uses Lua as a wrapper to expose its core C libraries; PyTorch eschews Lua (in favor of Python) for the same purpose.\nOnce you factor in the preeminence of Python, the rising popularity of PyTorch makes a lot of sense.\nThis may have something to do with TensorFlow\u2019s outsized presence in ML, too. In 2019, it accounted for 1% of all usage, about a third as much usage as machine learning and 22% of all AI/ML usage. TensorFlow isn\u2019t a Python-exclusive technology\u2014it exposes stable C and Python APIs[5]\u2014but its users tend to be Python-savvy and its related projects, patterns, tutorials, etc., disproportionately involve Python.\nThe results of our recent AI adoption survey underscore this trend. TensorFlow was also the No. 1 ML technology in the survey, while PyTorch came in at No. 4. Two additional Python-based tools (scikit-learn and Keras) also cracked the top five[6]. We know from our annual analysis of usage and search on the O\u2019Reilly online learning platform that one of Python\u2019s fastest areas of growth is in ML- and AI-related development. The prominence of these and other Python-related tools attests to this fact.\nWhat\u2019s in a name? The shift to \u201cartificial intelligence\u201d\nDoes the growing engagement in neural networks, reinforcement learning, unsupervised learning, and the increased focus on putting models into production augur a shift in how practitioners in the space frame what they do? We think yes, with practitioners increasingly calling their work \u201cartificial intelligence\u201d\u2014a notion supported by the growth in AI usage on O\u2019Reilly, the increasing embrace of sophisticated tools, and the empirical trend of putting those tools into production, which we see in our AI surveys.\nAI has always been the general term for building intelligent systems, with machine learning covering the more specific case of building software that learns and modifies its outputs without the need for additional coding. Here are some examples of what, when viewed in aggregate, helps explain why those in the space think machine learning doesn\u2019t quite cover all they do:\n\nMachine learning produces models that are widely used in the automation of tasks such as credit scoring, fraud detection, recommendation engines, etc., but ML models are increasingly deployed in libraries or services and exposed via APIs\u2014such that a model or ensemble of models can be invoked by any valid user, program, or service.\nTo some extent, models can be built with an aim toward reuse, such that, for example, a data profiling model can be invoked and used to support different business use cases.\nTools and techniques like reinforcement learning and unsupervised learning open up new use cases, including decision support, interactive games, real-time retail recommendation engines, and data discovery.\nThe focus of usage\u2014and, with it, design and development\u2014is shifting from the specific to the generalized. ML libraries and services have the potential to transform the software products we deliver, the processes that consume them, and\u2014concomitant with this\u2014the experiences of users, customers, partners, etc., alike.\nThis isn\u2019t just ML; it\u2019s a kind of AI: a new way of thinking about and applying machine intelligence. It has implications for software architecture, infrastructure, and operations\u2014for virtually all domains.\n\nSo, this isn\u2019t artificial general intelligence, but AI as the application of machine learning to solve problems, increase productivity, accelerate processes, and in many cases deliver wholly new products and services.\nConcluding thoughts\nAs organizations adopt analytic technologies, they\u2019re discovering more about themselves and their worlds. Adoption of ML, especially, prompts people at all levels of an organization to start asking questions that challenge in different ways what the organization thinks it knows about itself.\nAn organization\u2019s use of ML tools and techniques, and the contexts in which it uses them, will tend to change, too. For example, the techniques of supervised learning are useful for classifying known-knowns and for elucidating certain kinds of known-unknowns; they\u2019re unsuitable for surfacing unknown-unknowns, however. Unsupervised techniques are better for this. Not for classifying, synthesizing, or understanding unknown-unknowns\u2014that\u2019s the responsibility of human intelligence\u2014but for surfacing them in the first place. The upshot is that adopters are integrating both kinds of learning into their ML practices. They\u2019re also apt to experiment with advanced ML methods\u2014such as deep learning\u2014that have applications for both supervised and unsupervised learning. In fact, we found in our AI adoption survey that those new to ML are almost as likely to experiment with deep learning as mature adopters.\nRight now, companies are successfully using ML to ferret out known-unknowns and unknown-unknowns in their business worlds. They\u2019re instantiating what they discover, analyze, and understand about their worlds in models. Some are also starting to incorporate these models into automated, quasi-intelligent products, services, and software. All of this partakes of the propulsive logic of self-discovery. It\u2019s at the root of a question Plato first formulated almost 2,500 years ago: \u201cBut how will you look for something when you don\u2019t in the least know what it is?\u201d he has Meno ask Socrates. \u201cHow on earth are you going to set up something you don\u2019t know as the object of your search?\u201d\nPhilosophical tradition treats this question as a paradox. It\u2019s also possible to see it as an inquiry into how an object of knowledge augments and transforms itself. With ML and AI, we\u2019re training machines to surface new objects of knowledge that help us as we learn to ask new, different, and sometimes difficult questions about ourselves. By all indications, we seem to be having some success with this.\n\n\n[1] This article is based on non-personally-identifiable information about the top search terms and most-used topics on O\u2019Reilly online learning. We compared aggregated data for the last three years; a full year of data for 2017 and 2018, and through the end of October for 2019.\n[2] Overall usage share for the unsupervised learning topic on O\u2019Reilly more than tripled year-over-year. For the platform as a whole, unsupervised learning accounts for an extremely small percentage of usage activity\u2014< 0.1%. Share for specific applications (e.g., deep learning) is much higher.\n[3] Neural networks and deep learning are not exclusive to unsupervised learning. However, research into either topic is likely to surface the connection to unsupervised learning, as well as to reinforcement learning, transfer learning, etc.\n[4] In \u201cAI adoption in the enterprise 2020\u201d we found that two thirds of mature AI adopters and 55% of organizations that are evaluating AI are using deep learning.\n[5] TensorFlow supports stable C and Python APIs. The project supports API-level access in other languages\u2014including C++, Go, Java, and JavaScript\u2014but does not guarantee compatibility with them.\n[6] Neither scikit-learn nor Keras generated significant activity on the O\u2019Reilly platform itself, however. By contrast, in our 2020 AI adoption survey, the scikit-learn library (No. 2) was used by about 48% of respondents in 2019 and 2020. Keras, a Python library used in developing neural networks, climbed to No. 5 in the 2020 edition of the survey; it was used by more than one-third of all respondents.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/fqGcC2mtuhI/"
 },
 {
  "title": "Four short links: 19 March 2020",
  "content": "\nDos and Don\u2019ts in Open Source (Olaf Geirsson) \u2014 really useful advice to would-be contributors and project owners. It\u2019s tempting to respond to a welcome contribution with a quick, \u201cThis looks amazing, I will review tomorrow!\u201d Consider giving a thumbs-up reaction instead and wait with commenting until you complete the review. Promises are estimates and estimates are hard. Unless I\u2019m bound by a paid contract, I try to avoid promising my future time no matter how confident I am about delivering on the promise.\nThread on AI Content Moderation (Sarah T. Roberts) \u2014 content moderators can\u2019t work from home (she explains why), so Facebook is leaning hard on its AI systems, which are triggering false positives (censoring things it shouldn\u2019t) and people are noticing. It will be interesting to see how the systems improve, how people react, and whether we go back to human teams of moderators at the same scale we had before (with the accompanying mental damage to them).\nZoom Community Calls (Alex L. Miller) \u2014 how to configure your Zoom session for maximum audience fun but minimal exposure to trolling.\nHow to Survive Self-Isolating Without Losing It (Kate Montgomery) \u2014 from someone with years of experience. There are now many of these guides to maintaining mental health during isolation, and you should read a few (before the isolation starts, if you\u2019re in a position to do so, to prep for it). They\u2019re also worth reading if you now work from home, because it can end up being remarkably similar.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/DoxRc12sFEA/"
 },
 {
  "title": "AI adoption in the enterprise 2020",
  "content": "Last year, when we felt interest in artificial intelligence (AI) was approaching a fever pitch, we created a survey to ask about AI adoption. When we analyzed the results, we determined the AI space was in a state of rapid change, so we eagerly commissioned a follow-up survey to help find out where AI stands right now. The new survey, which ran for a few weeks in December 2019, generated an enthusiastic 1,388 responses. The update sheds light on what AI adoption looks like in the enterprise\u2014 hint: deployments are shifting from prototype to production\u2014the popularity of specific techniques and tools, the challenges experienced by adopters, and so on. There\u2019s a lot to bite into here, so let\u2019s get started.\nKey survey results:\n\nThe majority (85%) of respondent organizations are evaluating AI or using it in production[1]. Just 15% are not doing anything at all with AI.\n\n\nMore than half of respondent organizations identify as \u201cmature\u201d adopters of AI technologies: that is, they\u2019re using AI for analysis or in production.\nSupervised learning is the most popular ML technique among mature AI adopters, while deep learning is the most popular technique among organizations that are still evaluating AI.\nThough a problem, the lack of ML and AI skills isn\u2019t the biggest impediment to AI adoption. Almost 22% of respondents identified a lack of institutional support as the most significant issue.\nFew organizations are using formal governance controls to support their AI efforts.\n\nThe takeaway: AI adoption is proceeding apace. Most companies that were evaluating or experimenting with AI are now using it in production deployments. It\u2019s still early, but companies need to do more to put their AI efforts on solid ground. Whether it\u2019s controlling for common risk factors\u2014bias in model development, missing or poorly conditioned data, the tendency of models to degrade in production\u2014or instantiating formal processes to promote data governance, adopters will have their work cut out for them as they work to establish reliable AI production lines.\nRespondent demographics\nSurvey respondents represent 25 different industries, with \u201cSoftware\u201d (~17%) as the largest distinct vertical. The sample is far from tech-laden, however: the only other explicit technology category\u2014\u201cComputers, Electronics, & Hardware\u201d\u2014accounts for less than 7% of the sample. The \u201cOther\u201d category (~22%) comprises 12 separate industries.\nFigure 1. Industry of survey respondents.\nData scientists dominate, but executives are amply represented\nOne-sixth of respondents identify as data scientists, but executives\u2014i.e., directors, vice presidents, and CxOs\u2014account for about 26% of the sample. The survey does have a data-laden tilt, however: almost 30% of respondents identify as data scientists, data engineers, AIOps engineers, or as people who manage them. What is more, almost three-quarters of survey respondents say they work with data in their jobs. All told, more than 70% of respondents work in technology roles.\nFigure 2. Role of survey respondents.\nRegional breakdown\nClose to 50% of respondents work in North America, most of them in the United States, which by itself is home to almost 40% of survey participants. Western Europe (~23%) was the next largest region, followed by Asia at 15%. Participants from South America, Eastern Europe, Oceania, and Africa account for roughly 15% of responses.\nAnalysis: The state of AI adoption today\nMore than half of respondent organizations are in the \u201cmature\u201d phase of AI adoption (using AI for analysis/production), while about one-third are still evaluating AI[2]. This is close to a mirror image of last year\u2019s AI survey results, when 54% of respondent organizations were evaluating AI and just 27% were in the \u201cmature\u201d adoption phase. This year, about 15% of respondent organizations are not doing anything with AI, down ~20% from our 2019 survey.\nThe upshot is that 85% of organizations are using AI, and (of these) most are using it in production. It seems as if the experimental AI projects of 2019 have borne fruit. But what kind?\nFigure 3. Where AI projects are being used within companies.\nThe bulk of AI use is in research and development\u2014cited by just under half of all respondents\u2014followed by IT, which was cited by just over one-third. (Respondents were encouraged to make multiple selections.) Another high-use functional area is customer service, with just under 30% of share. Two functional areas\u2014marketing/advertising/PR and operations/facilities/fleet management\u2014see usage share of about 20%. Clearly respondent organizations see the value of AI in a raft of different functional organizations, and the flat results from last year show a consistency to that pattern.\nCommon challenges to AI adoption\nThe acquisition and retention of AI-specific skills remains a significant impediment to adoption in most organizations. This year, slightly more than one-sixth of respondents cited difficulty in hiring/retaining people with AI skills as a significant barrier to AI adoption in their organizations. This is down, albeit slightly, from 2019, when 18% of respondents blamed an AI skills gap for lagging adoption.\nFigure 4. Bottlenecks to AI adoption.\nBelieve it or not, a skills gap isn\u2019t the biggest impediment to AI adoption. In 2020, as in 2019, a plurality of respondents\u2014almost 22%\u2014identified a lack of institutional support as the biggest problem. In both 2019 and 2020, the AI skills gap actually occupied the No. 3 slot; this year, it trailed \u201cDifficulties in identifying appropriate business use cases,\u201d which was cited by 20% of respondents.\nA more detailed look at the bottleneck data shows executives selecting an unsupportive culture less often (15%) than the practitioners and managers (23%) who responded to the survey.\nFigure 5. Bottlenecks to AI adoption with AI maturity level.\nBy a 2:1 margin, respondents in companies that are evaluating AI are much more likely to cite an unsupportive culture as the primary bulwark to AI adoption. This disparity is striking\u2014and intriguing. Is it just the case that late-adopters are ipso facto more resistant to\u2014less open to\u2014AI?\nBy contrast, AI adopters are about one-third more likely to cite problems with missing or inconsistent data. We saw in our \u201cState of Data Quality in 2020\u201d survey that ML and AI projects tend to surface latent or hidden data quality issues, with the result that organizations that are using ML and AI are more likely to identify issues with the quality or completeness of their data. The logic in this case partakes of garbage-in, garbage out: data scientists and ML engineers need quality data to train their models. Companies evaluating AI, by contrast, may not yet know to what extent data quality can create AI woes.\nAI/ML skill shortages: Consistent and persistent\nWe asked survey respondents to identify the most critical ML- and AI-specific skills gaps in their organizations. The shortage of ML modelers and data scientists topped the list, cited by close to 58% of respondents. The challenge of understanding and maintaining a set of business use cases came in at number two, cited by almost half of participants. (Survey takers could choose more than one selection.) Close to 40% selected data engineering as a practice area for which skills are lacking. Finally, just under one quarter highlighted a lack of compute infrastructure skills.\nFigure 6. AI/ML skills gaps within organizations.\nThe most remarkable thing about these results is their year-over-year consistency. The same skill areas that were problematic in 2019 are again problematic in 2020\u2014and by about the same margins. In 2019, 57% of respondents cited a lack of ML modeling and data science expertise as an impediment to ML adoption; this year, slightly more\u2014close to 58%\u2014did so. This is true of other in-demand skills, too. The uncomfortable truth is that the most critical skill shortages cannot easily be addressed. The data scientist, for example, is a hybrid creature: ideally, she should possess not only theoretical and technical expertise, but practical, domain-specific business expertise, too.\nThis last is almost always acquired in practice, with the result that the freshly minted data scientist is invariably trained on the job. This helps explain why the proportion of respondents who cited a shortage of people skilled in understanding and maintaining business use cases increased year over year, from 47% in 2019 to 49% this year. The data scientist uses her domain-specific expertise to identify appropriate business use cases for AI. The ML modeler supplements her technical competency with domain-specific business knowledge that she accrues in practice. Both types of practitioner must also develop soft skills in team work, listening, and, most important, empathy. This takes time and is a function of experience.\nManaging AI/ML risk\nWe asked respondents to select all of the applicable risks they try to control for in building and deploying ML models. The results suggest that all organizations\u2014especially those with \u201cmature\u201d AI practices\u2014are alert to the risks inherent in the design and use of ML and AI technologies.\nFigure 7. Risks checked for during ML model building and deployment (with AI adoption maturity level).\nUnexpected outcomes/predictions was the single most common risk factor, cited by close to two-thirds of mature\u2014and by about 53% of still-evaluating\u2014AI practitioners. Among mature adopters, the need to control for the interpretability and transparency of ML models was the second most common risk factor (cited by about 55%); by contrast, a different option\u2014fairness, bias, and ethics (~40%)\u2014was the No. 2 risk factor among companies still evaluating AI. It ranks high (No. 3) with mature AI practitioners, too: ~48% check for fairness and bias during model building and deployment.\nMature AI practitioners are significantly more likely to implement checks for model degradation than companies that are still evaluating AI. Model degradation is the No. 4 risk factor among mature adopters (checked for by about 46%); however, it is next to last among organizations that are in the evaluation phase of AI adoption\u2014finishing ahead of the \u201cOther compliance\u201d category.\nThese risk factors are common, well understood, and don\u2019t stand alone. With respondents able to pick \u201call that apply\u201d to the question, we find that 41% of respondents list at least four issues, and 61% select at least three issues.\nSupervised learning is dominant, deep learning continues to rise\nSupervised learning remains the most popular ML technique among all adopters. In 2019, more than 80% of mature adopters\u2014and two-thirds of respondent organizations that were then evaluating AI\u2014used it. And in 2020, almost 73% of self-identified \u201cmature\u201d AI practices are using it. (The survey questionnaire encouraged respondents to select all applicable techniques.)\nFigure 8. AI technologies organizations are using (with AI adoption maturity level).\nThis year, however, deep learning displaced supervised learning as the most popular technique among organizations that are in the evaluation phase of AI adoption. To wit: in respondent organizations that are evaluating AI, slightly more say they\u2019re using deep learning (~55%) than supervised learning (~54%). And close to 66% of respondents who work for \u201cmature\u201d AI adopters say they\u2019re using deep learning, making it the second most popular technique in the mature cohort\u2014behind supervised learning.\nIt\u2019s true that usage of all ML or AI techniques is greater among mature adopters than among organizations still evaluating AI. That said, there are a number of striking differences between mature and less mature AI adopters. For example, about 23% of \u201cmature\u201d AI practices use transfer learning, nearly double the rate of usage in less mature practices (12%). Human-in-the-loop AI models are considerably more popular among mature users than among those still evaluating AI.\nSelecting the right tool for the job has more than three-quarters (78%) of respondents selecting at least two of ML techniques, 59%, using at least three, and 39% choosing at least four.\nThe dominant tools aren\u2019t getting any less dominant\nTensorFlow remains, by far, the single most popular tool for use in AI-related work. It was cited by almost 55% of respondents in both 2019 and 2020, which gives it a creditable consistency over time.\nTensorFlow\u2019s staying power also reinforces the fact that deep learning and neural networks\u2014with which it is strongly associated\u2014are far from niche techniques.\nFigure 9. AI tools organizations are using.\nThe most popular tools for AI development in 2019 were once again predominant in 2020. This could be a function of what we\u2019ll call the \u201cPython factor,\u201d however: four of the five most popular tools for AI-related work are either Python-based or dominated by Python tools, libraries, patterns, and projects.\nOf these, TensorFlow, scikit-learn, and Keras held steady, while PyTorch grew its share to more than 36%. This tracks with usage and search activity on the O\u2019Reilly online learning platform, where interest in PyTorch has grown quickly from a relatively small base. Our analysis of Python-related activity on O\u2019Reilly likewise shows that Python is seeing explosive growth in ML and AI-related development.\nData governance isn\u2019t yet a priority\nSlightly more than one-fifth of respondent organizations have implemented formal data governance processes and/or tools to support and complement their AI projects. This is consistent with the results of our data quality survey.\nThe good news is that just over 26% of respondents say their organizations plan to instantiate formal data governance processes and/or tools by 2021; almost 35% expect this to happen in the next three years. The bad news is that AI adopters\u2014much like organizations everywhere\u2014seem to treat data governance as an additive rather than an essential ingredient.\nIdeally, data provenance, data lineage, consistent data definitions, rich metadata management, and other essentials of good data governance would be baked into, not grafted on top of, an AI project.\nThink of data governance as analogous to observability in software development: it is easier to build a capacity for observability into a system than to retrofit an existing system to make it observable. In the same way, it is easier to build a capacity for data governance into a system or service than to \u201cadd\u201d it after the fact. Data governance is a data-specific take on observability that not only permits traceability and reproducibility, but permits transparency into what an AI asset is doing\u2014and how it\u2019s doing it.\nTakeaways\nA review of the survey results yields a few takeaways organizations can apply to their own AI projects.\n\nIf you do not have plans to evaluate AI, it\u2019s time to think about catching up. With an abundance of open source tools, libraries, tutorials, etc., not to mention an accessible lingua franca\u2014Python\u2014the bar for entry is actually pretty low. Most companies are experimenting with AI\u2014why risk being left behind?\nAI projects align with dominant trends in software architecture and infrastructure and operations. AI features can be decomposed into functional primitives and instantiated as microservices\u2014e.g., data cleansing services that profile data and generate statistics, perform deduplication and fuzzy matching, etc.\u2014or function-as-a-service designs.\nThink broadly: AI is used everywhere, not just in R&D and IT. A large share of survey respondents use AI in customer service, marketing, operations, finance, and other domains.\nTrain your organization, too\u2014not just your models. Institutional support remains the biggest barrier to AI adoption. If you think AI can help, you should spend time explaining how, why, and what to expect.\nThe risks associated with AI implementation are consistent and now better understood. The upshot is that it\u2019s easier to explain to executives and stakeholders what to expect in implementing AI projects.\n\nConcluding thoughts\nClearly, we see AI practices maturing, even if many production use cases appear primitive. Adopters are also taking proactive steps to control for the most common risk factors. Both mature and not-so-mature adopters are experimenting with sophisticated techniques to build their AI products and services. Adopters are using a wide variety of ML and AI tools, but have coalesced around a single language\u2014the ubiquitous, irrepressible Python. However, organizations need to address important data governance and data conditioning to expand and scale their AI practices.\n\n\n[1] We define \u201cproduction\u201d as the use of AI models in deployed applications that either serve users or are exposed as part of an automated, repeatable process\u2014such as data collection, profiling, cleansing, and engineering. This is distinct from AI models that are used for static predictive analytics, categorization studies, natural language tasks, or for other analytic purposes.\n[2] We asked participants to distinguish between \u201cmature\u201d adoption and \u201cevaluation\u201d on the basis of the following criteria: \u201cNone\u201d (no use of AI in any projects); \u201cEvaluation\u201d (limited to trial evaluations and proofs-of-concept); \u201cAnalysis\u201d (exploring, classifying, summarizing, and organizing data); and \u201cProduction\u201d (revenue-bearing AI projects that are used in production). We group those respondents that selected \u201cAnalysis\u201d and \u201cProduction\u201d into our \u201cmature\u201d cohort.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/51j23cc8IHc/"
 },
 {
  "title": "It\u2019s an unprecedented crisis: 8 things to do right now",
  "content": "Even with a stellar crisis plan, the COVID-19 pandemic presents a set of challenges unprecedented in our lifetimes. We don\u2019t know what\u2019s going to happen, and we\u2019re dealing with something growing exponentially, creating uncertainty on a global scale. I managed a team of 40 in Singapore during SARS. That crisis was different, hitting Singapore and a handful of other cities. But plenty of parallels exist: it was a health crisis, and the lessons learned might serve you and your organization well now. Here are some things to do immediately, including addressing issues around remote work, to ensure that business continues as usual.\n\nThis is your full-time job right now. Whatever was on your priority list last month, isn\u2019t anymore. This is your full-time job right now. That means you may need to tell the C-suite that their pet project has been delayed, and you may need to tell employees that performance reviews and team meetings are on hold. You and your team may be working very long days in the coming weeks.\nPush communications twice a day. In the arc of a crisis, we don\u2019t know quite where we are\u2014and that uncertainty can cause panic for some employees. News is coming out fast and good information is hard to come by. Create a morning and late afternoon update so your people know you are paying attention to their well-being. Share new information and repeat facts you already know. As we move from crisis to recovery\u2014and we will recover\u2014your updates can move from twice a day back to once a day and, then, less often.\nLet go of perfection. It\u2019s better to send out a revised set of rules everyday rather than being silent for days while executives try to land on the perfect policy and ideal language. Modify standard policies and make exceptions to long-held rules. Be transparent\u2014it\u2019s OK not to have all the answers because there are few definitive answers. Be transparent and say what you know and admit what you don\u2019t know.\nMonitor the CDC and your state health authorities. There will be rumors, fake news, and speculation. The only thing we know is that we have never been through this before. In 1918 during the Spanish Flu, it took days to cross the Atlantic and antibiotics hadn\u2019t been invented. Because this is unprecedented in our modern world, the CDC and your state health authorities are doing admirable work providing the most reliable and trustworthy information.\nPeople will respond very differently\u2014prepare for that to cause problems. Some people may begin refusing to come to work\u2014others might seem cavalier about COVID19. That divide may create serious friction in your organization. People who come to work begin to resent those who don\u2019t. Those who stay home begin to believe that some of their co-workers don\u2019t care about the health of families. After SARS, it took a long time to heal this split in the office. Acknowledge the split and that both points of view are valid.\nCreate new remote work guidelines\u2014today. It doesn\u2019t matter if you change these guidelines (see #3), just put out some basics. Is there a daily meeting? Will teams need to check in every day? What tools should they use? Should all meeting participants turn on their video? Whatever you decide\u2014put out some guidelines so people have a place to start. You can modify these tomorrow and completely rewrite them when the crisis passes.\nWe may not return to \u201cbusiness as usual.\u201d You are going to want to reassure people, and that may be an important part of your job. Tell people it will be OK\u2014because it will. But be careful: don\u2019t make any promises, because \u201cOK\u201d may not mean what it used to mean. Companies will likely make changes during the crisis or as things begin to recover. And, this may be an opportunity to change how your organization works. You are going to learn things about how your people learn, adapt, and improvise that will inform the new future.\nTake care of yourself. This is a marathon not a sprint. And, to carry that metaphor forward, we don\u2019t know the course of the marathon. We know some of you have been working around the clock\u2014that\u2019s not going to end tomorrow. If you aren\u2019t healthy and grounded, you can\u2019t see your team through this. Ground yourself; whatever gives you peace and contentment\u2014you need that now, for you, for your family, and for the demands of your work.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/zsrywhHLzI8/"
 },
 {
  "title": "Four short links: 18 March 2020",
  "content": "\nInklewriter \u2014 open source interactive text adventure game creator. (Fun for adults, but also great to give to kids who love to read) (via Andy Baio)\nThe Virus Survival Strategy Guide for Your Startup (Steve Blank) \u2014 Unfortunately, it\u2019s no longer a normal market. All your assumptions about customers; sales cycle; and, most importantly, revenue, burn rate, and runway are no longer true. If you\u2019re a startup, you\u2019ve likely calculated your runway to last until you raise your next round of funding. Assuming there was going to be a next round. That may be no longer true.\nFree Cambridge University Textbooks \u2014 all available in HTML for free (gratis) until the end of May.\nSoftware Engineering at Google \u2014 a new O\u2019Reilly book. Covers Google\u2019s unique engineering culture, processes, and tools, and how these aspects contribute to the effectiveness of an engineering organization.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/FQ2S_dHbHTs/"
 },
 {
  "title": "Four short links: 17 March 2020",
  "content": "\nHow the Great Firewall Discovers Hidden Circumvention Servers \u2014 really interesting CCC talk from a few years ago.\nThe Challenge of Software Liability \u2014 Liability for insecure software is already a reality. The question is whether Congress will step in to give it shape and a coherent legal structure.\nXOXO Talks \u2014 video archive of past talks. Suitable for the long nights of social isolation.\nSelected Research Papers on Internet Censorship \u2014 Most papers on CensorBib approach the topic from a technical angle, by proposing designs that circumvent censorship systems, or by measuring how censorship works.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/3XhdFqZsNS8/"
 },
 {
  "title": "Four short links: 16 March 2020",
  "content": "\nThe Uncensored Library \u2014 Reporters Without Borders built a library in Minecraft, in which you can read banned books. (via Gizmodo)\nShmoocon 2020 Talk Recordings \u2014 everything from email addresses to Verilog by way of Zero Trust, social media, and choose-your-own-adventure ransomware.\nDifferential Privacy: A Comparison of Libraries \u2014 We will have a look at how the dataset size affects accuracy and how the desired privacy level (epsilon) affects data accuracy. For each case, we will compare the results obtained using the various differential privacy libraries.\nLayoffs are Coming (Jacob Kaplan-Moss) \u2014 who is likely to get laid off and how to prepare, from a web elder who has lived through two recessions.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/3tj3NiTXThA/"
 },
 {
  "title": "Four short links: 13 March 2020",
  "content": "\nOpenAM \u2014 an open-access management solution that includes authentication, SSO, authorization, federation, entitlements and web services security.\nBuilding Relationships as a Remote Engineering Manager \u2014 And if you haven\u2019t realized it yet, get used to this\u2014you\u2019re going to spend a lot of time writing.\nAPI Security Maturity Model \u2014 I\u2019m not sure if I agree with this specific framework, but I like the idea of a maturity model for APIs in general and security in particular. Level 0 \u2013 API Keys and Basic Authentication; Level 1 \u2013 Token-Based Authentication; Level 2 \u2013 Token-Based Authorization; Level 3 \u2013 Centralized Trust Using Claims.\nHexagonal Architecture (Netflix) \u2014 The idea of Hexagonal Architecture is to put inputs and outputs at the edges of our design. Business logic should not depend on whether we expose a REST or a GraphQL API, and it should not depend on where we get data from\u2014a database, a microservice API exposed via gRPC or REST, or just a simple CSV file. How Netflix used this architectural concept in practice.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/qlfo450nz88/"
 },
 {
  "title": "Four short links: 12 March 2020",
  "content": "\nAWS Bill Analysis \u2014 always interesting to see how to approach lowering your costs. In this case, the project owner works for Amazon on AWS, but still there were savings to be had.\nA Design Guide to Writing Offline-first Apps \u2014 In this article, we will be diving into some of the engineering challenges that make designing robust offline-first applications with good user experience hard, and explore some architectures.\nZero Trust Information \u2014 To that end, instead of trying to fight the internet\u2014to try to build a castle and moat around information, with all of the impossible tradeoffs that result\u2014how much more value might there be in embracing the deluge? The either-or is a false frame: you can fight the worst without giving up the best. (I think Ben and I would agree that limiting access to encryption is a bad idea.)\nHow Some Good Corporate Engineering Blogs Are Written (Dan Luu) \u2014 In order to have a boring blog, the corporation has to actively stop engineers from putting interesting content out there. Unfortunately, it appears that the natural state of large corporations tends toward risk aversion and blocking people from writing, just in case it causes a legal or PR or other problem. Presents the process at a couple of different companies with interesting blogs, and some with boring blogs.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/wpmmdqTildY/"
 },
 {
  "title": "Four short links: 11 March 2020",
  "content": "\nPluralistic \u2014 Cory Doctorow\u2019s news site and newsletter, where you can learn about African WhatsApp modders among other things.\nMapnik \u2014 LGPLed software that combines pixel-perfect image output with lightning-fast cartographic algorithms, and exposes interfaces in C++, Python, and Node.\npi node \u2014 A \u03c0-box is a modular system of radio/streaming broadcast, composed of multiples inputs and outputs. The \u03c0-box aims to provide a multi-functional and easy-to-use micro-FM and streaming micro radio station. It is based on the mini-FM approach developed in the 80\u2019s by the Japanese artist and researcher Tetsuo Kogawa, which promotes radio transmissions of FM waves upon a tiny perimeter, such as a house, a block, or a small zone. The \u03c0-box combines this ultra local transmission with internet possibilities (through ethernet, Wi-Fi or 3G/4G) to leverage all the possibilities of hybrid transmissions. The system is open source and based on open source software / open hardware.\nAutoML-Zero \u2014 evolutionary search by modifying basic math operations with minimal human direction: evolutionary search shows promising results by discovering linear regression with gradient descent, 2-layer neural networks with backpropagation, and even algorithms that surpass hand-designed baselines of comparable complexity. Code available.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/zPAuddHbgXk/"
 },
 {
  "title": "Four short links: 10 March 2020",
  "content": "\nMLflow \u2014 an open source platform to manage the ML lifecycle, including experimentation, reproducibility, and deployment. It currently offers three components: tracking, projects, and models.\nEventing Facets (Tim Bray) \u2014 the word \u201ceventing\u201d makes my skin crawl, but this series of posts has A+ info in it.\nWorkbox \u2014 JavaScript Libraries for adding offline support to web apps, from Google.\nTensorFlow Quantum \u2014 a library for hybrid quantum-classical machine learning. See also arXiv paper, Google AI Blog, and source.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/RXf9JHAKX3s/"
 },
 {
  "title": "Four short links: 9 March 2020",
  "content": "\nSno \u2014 Distributed version control\nfor geospatial and tabular data. Finally, git for (geo)data done right. Open source.\nThe Woman Worked as a Babysitter: On Biases in Language Generation \u2014 plugging prompts like \u201cthe woman worked as\u201d and \u201cthe white person worked as\u201d into text generation systems, and the horrors you get back. (via Violent Peng)\nHow to Run a Free Online Academic Conference: A Workbook \u2014 as f2f conferences are canceled left, right, and center, this might be of interest to folks. (via Franklin Sayre)\nSolving 11 Likely Problems in Your Multithreaded Code \u2014 There really is a fundamental set of concepts that you need to learn and become comfortable with. It\u2019s likely that certain languages and libraries can hide some concepts over time, but if you\u2019re doing concurrency today, you won\u2019t have that luxury. This article describes some of the more common challenges to be aware of and presents advice for coping with them in your software.\n\n",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/ohtN5Y_peBg/"
 }
]